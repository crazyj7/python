{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train car - v4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data ; crop and resize  \n",
    "network ; xception , decrease batch_size. \n",
    "\n",
    "ImageAugment  ; shift add. \n",
    "random_eraser ; image part remove\n",
    "\n",
    "batch 32\n",
    "earlystop ; f1_score \n",
    "checkpoint best save \n",
    "\n",
    "train acc;  , val acc;  , lb acc;   \n",
    "model1 ;  96, 84\n",
    "model2;  96, 85\n",
    "model3 ; 95, 86\n",
    "\n",
    "enssamble. sum.\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications import xception\n",
    "from keras.preprocessing import image\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dropout, MaxPooling2D, Flatten, Dense, Softmax\n",
    "import random\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, K\n",
    "from keras.models import Input, Model\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache=False\n",
    "basedir = './'\n",
    "imgwidth=224\n",
    "imgheight=224\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# K fold\n",
    "fold_k = 5\n",
    "# current fold\n",
    "fold_c = 4   # 1~fold_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainall = np.load('x_train.npy')\n",
    "y_trainall = np.load('y_train.npy')\n",
    "dfclass = pd.read_csv(basedir+'class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelpath= car-v4-4.ckpt\n",
      "(7990, 224, 224, 3) (7990,) (2000, 224, 224, 3) (2000,)\n",
      "0 195\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "datacnt = x_trainall.shape[0]\n",
    "flagval = np.zeros(datacnt)\n",
    "modelpath = 'car-v4-'+str(fold_c)+'.ckpt'\n",
    "\n",
    "print('modelpath=', modelpath)\n",
    "flagval[(fold_c-1)*2000:(fold_c)*2000] = 1\n",
    "\n",
    "x_train = x_trainall[flagval==0]\n",
    "y_train = y_trainall[flagval==0]\n",
    "x_val = x_trainall[flagval==1]\n",
    "y_val = y_trainall[flagval==1]\n",
    "    \n",
    "del x_trainall\n",
    "del y_trainall\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n",
    "print(np.min(y_train), np.max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_onehot = np_utils.to_categorical(y_train, 196)\n",
    "y_val_onehot = np_utils.to_categorical(y_val, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://github.com/yu4u/cutout-random-erasing/blob/master/cifar10_resnet.py\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "        return input_img\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augumentation\n",
    "batch_size=32  # 32, 64\n",
    "datagen1 = ImageDataGenerator(rescale=1./255, shear_range=0.1, zoom_range=0.1, horizontal_flip=True, vertical_flip=False, \n",
    "                              width_shift_range=0.1, height_shift_range=0.1,\n",
    "                              fill_mode='nearest', preprocessing_function = get_random_eraser(v_l=0, v_h=1),)\n",
    "datagen2 = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = datagen1.flow(x_train, y_train_onehot, batch_size=batch_size)\n",
    "val_generator = datagen2.flow(x_val, y_val_onehot, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score \n",
    "def new_score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = (true_positives + K.epsilon()) / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = (true_positives + K.epsilon()) / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### checkpoint save weights in progress...\n",
    "cp_callback = ModelCheckpoint(modelpath,  monitor='val_new_score', mode='max', save_best_only=True, save_weights_only=True)\n",
    "es_callback = EarlyStopping(monitor='val_new_score',  mode='max', patience=20, min_delta=0.0001)\n",
    "\n",
    "# tensorboard log\n",
    "if not os.path.exists('log'):\n",
    "    os.mkdir('log')\n",
    "tensorboard = TensorBoard(log_dir='log/'+str(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(224,224,3))\n",
    "net = xception.Xception(input_tensor=inputs, input_shape=(224, 224, 3), include_top=False, weights='imagenet', pooling='max')\n",
    "net2 = Dense(224, activation='relu') (net.layers[-1].output)\n",
    "net2 = Dense(196)(net2)\n",
    "net2 = Softmax(196)(net2)\n",
    "model = Model(inputs=inputs, outputs=net2)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no freezing...\n"
     ]
    }
   ],
   "source": [
    "##### model freeze. after acc 90.\n",
    "if False:\n",
    "    print('freezing...')\n",
    "    for layer in model.layers[:-4]:\n",
    "        layer.trainable=False\n",
    "else:\n",
    "    print('no freezing...')\n",
    "#     for layer in model.layers:\n",
    "#         print(layer, layer.trainable)\n",
    "#     model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found weights... new\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(modelpath):\n",
    "    print('load weights...')\n",
    "    model.load_weights(modelpath)\n",
    "else:\n",
    "    print('not found weights... new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', new_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/psychic/.conda/envs/tensorgpu36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/psychic/.conda/envs/tensorgpu36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/500\n",
      " 14/249 [>.............................] - ETA: 3:00 - loss: 5.3591 - acc: 0.0000e+00 - new_score: 6.2500e-09"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-6d4a58b46876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m hist = model.fit_generator( train_generator, initial_epoch=0, epochs = 500, validation_data=val_generator, \n\u001b[1;32m      3\u001b[0m                            \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                            steps_per_epoch=len(x_train)/batch_size, validation_steps=len(x_val)/batch_size)\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# epochs = 100\n",
    "hist = model.fit_generator( train_generator, initial_epoch=0, epochs = 500, validation_data=val_generator, \n",
    "                           callbacks=[tensorboard, cp_callback, es_callback],\n",
    "                           steps_per_epoch=len(x_train)/batch_size, validation_steps=len(x_val)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7484233678579331, 0.846, 0.8513013396263123]\n"
     ]
    }
   ],
   "source": [
    "# hist = model.evaluate( x_val/255., y_val_onehot, batch_size=30, verbose=1 )\n",
    "hist = model.evaluate_generator(val_generator, steps=len(x_val)/batch_size)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('car-v4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data load for submission\n",
    "x_test = np.load('x_test.npy')\n",
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one model submission \n",
    "if False:\n",
    "    predictions = model.predict( x_test )\n",
    "    pdi = np.argmax(predictions, axis=1)\n",
    "    print(pdi, np.min(pdi), np.max(pdi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1: [[3.69458289e-14 1.11258962e-35 1.77841311e-30 ... 2.23007878e-13\n",
      "  1.40615340e-23 1.00434986e-23]\n",
      " [1.16716154e-20 3.41513017e-16 4.37719437e-15 ... 3.59256451e-18\n",
      "  5.38302753e-14 2.45638759e-10]\n",
      " [1.83429156e-23 4.70149961e-23 1.99139752e-19 ... 1.70155275e-27\n",
      "  7.28396137e-24 1.46811952e-17]\n",
      " ...\n",
      " [2.84027674e-27 2.25980703e-19 1.54869200e-19 ... 3.77228287e-20\n",
      "  6.34357586e-16 3.66114781e-28]\n",
      " [2.74565703e-16 3.95558224e-18 1.68523005e-18 ... 7.69631783e-20\n",
      "  1.92088345e-09 1.56790845e-12]\n",
      " [2.12169606e-22 1.42689730e-15 6.09978214e-12 ... 5.84064686e-24\n",
      "  1.16103016e-09 1.41565775e-23]]\n",
      "model2: [[3.43239437e-09 3.34558650e-36 7.07518992e-26 ... 6.44292454e-13\n",
      "  4.49355019e-23 7.84796395e-20]\n",
      " [9.17424760e-17 1.76205610e-20 1.21798364e-18 ... 3.95197028e-25\n",
      "  3.62783404e-24 1.63518965e-13]\n",
      " [7.78969576e-25 1.23197044e-29 2.47368342e-30 ... 2.27081043e-23\n",
      "  6.36523828e-25 5.76079336e-16]\n",
      " ...\n",
      " [2.27793794e-28 5.88929170e-17 2.78877802e-18 ... 9.08388287e-15\n",
      "  1.57846823e-17 1.65419992e-19]\n",
      " [6.70884876e-21 1.72441583e-20 9.58646617e-23 ... 4.93591097e-24\n",
      "  1.47381054e-15 1.26556880e-17]\n",
      " [1.35982095e-20 1.99068572e-13 1.14258872e-19 ... 1.11795237e-20\n",
      "  2.36618098e-13 6.30829566e-18]]\n",
      "model3: [[3.27942362e-09 1.91050811e-24 1.79848318e-18 ... 7.78207997e-14\n",
      "  2.22346710e-10 1.02893476e-13]\n",
      " [7.03348185e-20 1.79037802e-19 8.19317765e-17 ... 2.20385917e-18\n",
      "  9.71759904e-14 2.75180767e-10]\n",
      " [0.00000000e+00 3.67614937e-35 7.95140962e-37 ... 9.70227823e-32\n",
      "  4.75000453e-26 7.81907777e-18]\n",
      " ...\n",
      " [5.21365540e-34 2.66763880e-22 1.68079216e-28 ... 4.90141591e-21\n",
      "  1.08289432e-19 6.25466852e-30]\n",
      " [3.25018735e-36 4.37356729e-23 2.36808821e-25 ... 3.94064791e-25\n",
      "  1.91134594e-14 1.00785689e-20]\n",
      " [6.24616798e-19 1.33426201e-10 6.01604676e-14 ... 3.17636425e-18\n",
      "  5.19532402e-14 2.12080702e-15]]\n",
      "final: [123  97 156 ...  43  49  93] 0 195\n"
     ]
    }
   ],
   "source": [
    "# ensamble. submission.\n",
    "# model = load_mode('car-v4.h5')\n",
    "if True:\n",
    "#     mo = load_model(mp, custom_objects={'new_score': new_score})\n",
    "    inputs = Input(shape=(224,224,3))\n",
    "    net = xception.Xception(input_tensor=inputs, input_shape=(224, 224, 3), include_top=False, pooling='max')\n",
    "    net2 = Dense(224, activation='relu') (net.layers[-1].output)\n",
    "    net2 = Dense(196)(net2)\n",
    "    net2 = Softmax(196)(net2)\n",
    "    model = Model(inputs=inputs, outputs=net2)\n",
    "    predictions=[]\n",
    "    for ff in range(1, fold_k+1):\n",
    "        mp='car-v4-'+str(ff)+'.ckpt'\n",
    "        print('model',ff,':', mp)\n",
    "        model.load_weights(mp)\n",
    "        pr = model.predict( x_test )\n",
    "        predictions.append(pr)\n",
    "        print('prediction',ff,':',pr)\n",
    "    predictions = np.asarray(predictions)\n",
    "    prk = np.sum(predictions, axis=0 )\n",
    "    pdi = np.argmax(prk, axis=1)\n",
    "    print('final:', pdi, np.min(pdi), np.max(pdi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_file</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_00001.jpg</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_00002.jpg</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_00003.jpg</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_00004.jpg</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_00005.jpg</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         img_file  class\n",
       "0  test_00001.jpg    124\n",
       "1  test_00002.jpg     98\n",
       "2  test_00003.jpg    157\n",
       "3  test_00004.jpg     94\n",
       "4  test_00005.jpg     18"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(basedir+'sample_submission.csv')\n",
    "submission[\"class\"] = pdi + 1  # class [0,195] to [1,196]  \n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7ca0066d68>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(submission[\"class\"], order=submission[\"class\"].value_counts(ascending=True).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
