{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Submission\n",
    "\n",
    "# %% [markdown]\n",
    "# ## load package\n",
    "\n",
    "# %% [code]\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications import xception\n",
    "from keras.applications import resnet50\n",
    "from keras.applications import mobilenetv2\n",
    "# from efficientnet import EfficientNetB3\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dropout, MaxPooling2D, Flatten, Dense, Softmax\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, K\n",
    "from keras.models import Input, Model\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "bKaggle = True\n",
    "bDebug = False   # train data test.\n",
    "\n",
    "datadir = './pre/'\n",
    "modeldir = './pre/'\n",
    "inputdir='./'\n",
    "if bKaggle:\n",
    "    datadir = '../input/carmodel5/ppcarmodel/'\n",
    "    modeldir = '../input/carmodel6/model/'\n",
    "    inputdir = '../input/2019-3rd-ml-month-with-kakr/'\n",
    "\n",
    "print(modeldir)\n",
    "\n",
    "# %% [code]\n",
    "# 224/299\n",
    "imagesize=250\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "def dbgprint(msg):\n",
    "    if bKaggle:\n",
    "        os.system('echo \"'+msg+'\"')\n",
    "    else:\n",
    "        print(msg)\n",
    "\n",
    "dbgprint('hello log')\n",
    "\n",
    "# %% [code]\n",
    "# f1 score \n",
    "def new_score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = (true_positives + K.epsilon()) / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = (true_positives + K.epsilon()) / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Predict\n",
    "\n",
    "# %% [code]\n",
    "# test data load for submission\n",
    "\n",
    "if bDebug:\n",
    "    print('debug...')\n",
    "    dftrain = pd.read_csv(inputdir+'train.csv')\n",
    "    dftrain['class'] = dftrain['class'].astype('str')\n",
    "    dftest = dftrain.iloc[8000:,:]\n",
    "    targetdir = datadir+'train'\n",
    "else:\n",
    "    dftest = pd.read_csv(inputdir+'test.csv')\n",
    "    targetdir = datadir+'test'\n",
    "\n",
    "classes = list(str(num) for num in range(1,197))\n",
    "\n",
    "batch_size=32\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=dftest, \n",
    "                                             directory=targetdir,\n",
    "                                             x_col = 'img_file', \n",
    "                                             class_mode = None,\n",
    "                                             target_size = (imagesize, imagesize),\n",
    "                                             batch_size=batch_size, shuffle=False )\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "if True:\n",
    "    import glob, os\n",
    "    \n",
    "    predictions=[]\n",
    "    # 'carmodel-v8-1-', \n",
    "#     for ff, mp in enumerate(['carmodel-v8-6-', 'carmodel-v8-7-', 'carmodel-v8-8-']):\n",
    "    for ff, mp in enumerate(['carmodel-v5-1', 'carmodel-v5-2-']):\n",
    "        files = glob.glob(modeldir+mp+'*')\n",
    "        mp = max(files, key=os.path.getctime)\n",
    "        msg = '{} model={}'.format(ff, mp)\n",
    "        dbgprint(msg)\n",
    "        \n",
    "        method='xception'\n",
    "        if mp.find('resnet50')>0:\n",
    "            method = 'resnet50'\n",
    "        elif mp.find('mobilenetv2')>0:\n",
    "            method = 'mobilenetv2'\n",
    "        elif mp.find('efficientnetb3')>0:\n",
    "            method = 'efficientnetb3'\n",
    "        \n",
    "        inputs = Input(shape=(imagesize,imagesize,3))\n",
    "        print('method=', method)\n",
    "        if method=='xception':\n",
    "            net = xception.Xception(input_tensor=inputs, input_shape=(imagesize, imagesize, 3), include_top=False, weights='imagenet', pooling='max')\n",
    "        elif method=='resnet50':\n",
    "            net = resnet50.ResNet50(input_tensor=inputs, input_shape=(imagesize, imagesize, 3), include_top=False, weights='imagenet', pooling='max')\n",
    "        elif method=='mobilenetv2':\n",
    "            net = mobilenetv2.MobileNetV2(input_tensor=inputs, input_shape=(imagesize, imagesize, 3), include_top=False, weights='imagenet', pooling='max')\n",
    "        elif method=='efficientnetb3':\n",
    "            net = EfficientNetB3(input_tensor=inputs, input_shape=(imagesize, imagesize, 3), include_top=False, weights='imagenet', pooling='max')\n",
    "        net2 = Dense(256, activation='relu') (net.layers[-1].output)\n",
    "        net2 = Dense(196, activation='softmax')(net2)\n",
    "        model = Model(inputs=inputs, outputs=net2)\n",
    "        \n",
    "        print('model',ff,':', mp)\n",
    "        model.load_weights(mp)\n",
    "        \n",
    "        print('predict_generator')\n",
    "        test_generator.reset()\n",
    "        pr = model.predict_generator( test_generator , steps=len(dftest)/batch_size, verbose=1)\n",
    "        # steps=len(dftest)/batchsize\n",
    "        predictions.append(pr)\n",
    "        print('prediction',ff,':',pr)\n",
    "        print(pr.shape)        \n",
    "        \n",
    "\n",
    "# %% [code]\n",
    "print('dftest count=', len(dftest))\n",
    "print('model result count=', len(predictions))\n",
    "print('each result count=', predictions[0].shape)\n",
    "\n",
    "# %% [code]\n",
    "# �덉륫留� 諛섎났\n",
    "if False:\n",
    "    predictions=[]\n",
    "    test_generator.reset()\n",
    "    pr = model.predict_generator( test_generator , steps=len(dftest)/batch_size, verbose=1 )\n",
    "    # steps=len(dftest)/batchsize\n",
    "    predictions.append(pr)\n",
    "    print('prediction',ff,':',pr)\n",
    "    print(pr.shape)\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "print(np.argmax(predictions[0], axis=1))\n",
    "print(np.argmax(predictions[1], axis=1))\n",
    "\n",
    "# %% [code]\n",
    "if True:\n",
    "    predictions = np.asarray(predictions)\n",
    "    prk = np.mean(predictions, axis=0 )\n",
    "    pdi = np.argmax(prk, axis=1)\n",
    "    print('middle:', pdi, np.min(pdi), np.max(pdi))\n",
    "    \n",
    "    sns.countplot(pdi)\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "if True:\n",
    "    # labeling k=label string, v=class number\n",
    "#     label = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "#     final_pred = [label[k] for k in pdi]\n",
    "    \n",
    "    n1=pd.DataFrame(list(range(1,197)), columns=['num']).astype('str')\n",
    "    n2=n1.sort_values('num').values.squeeze()\n",
    "    final_pred = [n2[k] for k in pdi]\n",
    "    \n",
    "    final_pred = np.asarray(final_pred, dtype=np.int)\n",
    "    print('final:', final_pred)\n",
    "    print('count=', len(final_pred))    \n",
    "\n",
    "# %% [code]\n",
    "if bDebug:\n",
    "    reallabel = np.array(dftest['class'].values, dtype=int)\n",
    "    print(reallabel)\n",
    "    print( np.sum(final_pred==reallabel), '/', len(final_pred), len(reallabel))\n",
    "\n",
    "# %% [code] {\"jupyter\":{\"outputs_hidden\":true}}\n",
    "if not bDebug:\n",
    "    submission = pd.read_csv(inputdir+'sample_submission.csv')\n",
    "    submission[\"class\"] = final_pred  \n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    submission.head()\n",
    "\n",
    "    sns.countplot(submission[\"class\"], order=submission[\"class\"].value_counts(ascending=True).index)\n",
    "\n",
    "# %% [code]\n",
    "if False:\n",
    "    dfpredictions = pd.DataFrame(np.max(final_pred, axis=1).squeeze() )\n",
    "    dfpredictions.describe()\n",
    "    dfpredictions[0].plot.hist(bins=20)\n",
    "    psids = dfpredictions[0]>0.99 \n",
    "    np.sum(psids)\n",
    "\n",
    "# %% [code]\n",
    "# pseudo dataset\n",
    "# x_test[psids]\n",
    "# pdi[psids]\n",
    "# make pseudo\n",
    "if False:\n",
    "    print('Create Pseudo Label')\n",
    "    x_test = np.load(datadir+'x_test3.npy')\n",
    "    np.save('x_pseudo3.npy', x_test[psids])\n",
    "    np.save('y_pseudo3.npy', pdi[psids])\n",
    "\n",
    "# %% [code]\n",
    "\n",
    "\n",
    "# %% [code]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor36",
   "language": "python",
   "name": "tensor36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
