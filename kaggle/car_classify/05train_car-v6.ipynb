{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train car - v6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data ; crop and resize ; add margin!\n",
    "network ; xception \n",
    "\n",
    "ImageAugment  ; shift add. \n",
    "# random_eraser ; image part remove ; off\n",
    "\n",
    "batch 32\n",
    "earlystop ; f1_score \n",
    "checkpoint best save \n",
    "\n",
    "train acc;  , val acc;  , lb acc;   \n",
    "model1 ;  \n",
    "model2;  \n",
    "model3 ; \n",
    "\n",
    "enssamble. sum.\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications import xception\n",
    "from keras.preprocessing import image\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dropout, MaxPooling2D, Flatten, Dense, Softmax\n",
    "import random\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, K\n",
    "from keras.models import Input, Model\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache=False\n",
    "basedir = './'\n",
    "imgwidth=224\n",
    "imgheight=224\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# K fold\n",
    "fold_k = 5\n",
    "# current fold\n",
    "fold_c = 5   # 1~fold_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainall = np.load('x_train.npy')\n",
    "y_trainall = np.load('y_train.npy')\n",
    "dfclass = pd.read_csv(basedir+'class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelpath= car-v4-5.ckpt\n",
      "(8000, 224, 224, 3) (8000,) (1990, 224, 224, 3) (1990,)\n",
      "0 195\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "datacnt = x_trainall.shape[0]\n",
    "flagval = np.zeros(datacnt)\n",
    "modelpath = 'car-v4-'+str(fold_c)+'.ckpt'\n",
    "\n",
    "print('modelpath=', modelpath)\n",
    "flagval[(fold_c-1)*2000:(fold_c)*2000] = 1\n",
    "\n",
    "x_train = x_trainall[flagval==0]\n",
    "y_train = y_trainall[flagval==0]\n",
    "x_val = x_trainall[flagval==1]\n",
    "y_val = y_trainall[flagval==1]\n",
    "    \n",
    "del x_trainall\n",
    "del y_trainall\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n",
    "print(np.min(y_train), np.max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_onehot = np_utils.to_categorical(y_train, 196)\n",
    "y_val_onehot = np_utils.to_categorical(y_val, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://github.com/yu4u/cutout-random-erasing/blob/master/cifar10_resnet.py\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "        return input_img\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augumentation\n",
    "batch_size=32  # 32, 64\n",
    "# datagen1 = ImageDataGenerator(rescale=1./255, shear_range=0.1, zoom_range=0.1, horizontal_flip=True, vertical_flip=False, \n",
    "#                               width_shift_range=0.1, height_shift_range=0.1,\n",
    "#                               fill_mode='nearest', preprocessing_function = get_random_eraser(v_l=0, v_h=1),)\n",
    "datagen1 = ImageDataGenerator(rescale=1./255, shear_range=0.1, zoom_range=0.1, horizontal_flip=True, vertical_flip=False, \n",
    "                              width_shift_range=0.1, height_shift_range=0.1,\n",
    "                              fill_mode='nearest')\n",
    "datagen2 = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = datagen1.flow(x_train, y_train_onehot, batch_size=batch_size)\n",
    "val_generator = datagen2.flow(x_val, y_val_onehot, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score \n",
    "def new_score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = (true_positives + K.epsilon()) / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = (true_positives + K.epsilon()) / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### checkpoint save weights in progress...\n",
    "cp_callback = ModelCheckpoint(modelpath,  monitor='val_new_score', mode='max', save_best_only=True, save_weights_only=True)\n",
    "es_callback = EarlyStopping(monitor='val_new_score',  mode='max', patience=20, min_delta=0.0001)\n",
    "\n",
    "# tensorboard log\n",
    "if not os.path.exists('log'):\n",
    "    os.mkdir('log')\n",
    "tensorboard = TensorBoard(log_dir='log/'+str(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/psychic/.conda/envs/tensorgpu36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(224,224,3))\n",
    "net = xception.Xception(input_tensor=inputs, input_shape=(224, 224, 3), include_top=False, weights='imagenet', pooling='max')\n",
    "net2 = Dense(224, activation='relu') (net.layers[-1].output)\n",
    "net2 = Dense(196)(net2)\n",
    "net2 = Softmax(196)(net2)\n",
    "model = Model(inputs=inputs, outputs=net2)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no freezing...\n"
     ]
    }
   ],
   "source": [
    "##### model freeze. after acc 90.\n",
    "if False:\n",
    "    print('freezing...')\n",
    "    for layer in model.layers[:-4]:\n",
    "        layer.trainable=False\n",
    "else:\n",
    "    print('no freezing...')\n",
    "#     for layer in model.layers:\n",
    "#         print(layer, layer.trainable)\n",
    "#     model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', new_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(modelpath):\n",
    "    print('load weights...')\n",
    "    model.load_weights(modelpath)\n",
    "else:\n",
    "    print('not found weights... new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/psychic/.conda/envs/tensorgpu36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/psychic/.conda/envs/tensorgpu36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/500\n",
      "250/250 [==============================] - 109s 437ms/step - loss: 5.1234 - acc: 0.0106 - new_score: 6.2500e-09 - val_loss: 5.2796 - val_acc: 0.0121 - val_new_score: 6.1276e-09\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 103s 410ms/step - loss: 4.4498 - acc: 0.0411 - new_score: 4.8485e-04 - val_loss: 5.0951 - val_acc: 0.0382 - val_new_score: 0.0057\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 103s 410ms/step - loss: 3.7394 - acc: 0.0983 - new_score: 0.0110 - val_loss: 3.9467 - val_acc: 0.0874 - val_new_score: 0.0200\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 103s 411ms/step - loss: 3.0210 - acc: 0.1862 - new_score: 0.0553 - val_loss: 2.8290 - val_acc: 0.2236 - val_new_score: 0.1226\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 2.4196 - acc: 0.3166 - new_score: 0.1881 - val_loss: 2.9334 - val_acc: 0.2427 - val_new_score: 0.2056\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 1.8964 - acc: 0.4409 - new_score: 0.3620 - val_loss: 1.6958 - val_acc: 0.5070 - val_new_score: 0.4717\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 1.5408 - acc: 0.5260 - new_score: 0.4939 - val_loss: 1.7307 - val_acc: 0.4950 - val_new_score: 0.4735\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 1.2768 - acc: 0.6079 - new_score: 0.5819 - val_loss: 1.2141 - val_acc: 0.6432 - val_new_score: 0.6370\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 1.0443 - acc: 0.6715 - new_score: 0.6646 - val_loss: 1.4062 - val_acc: 0.6141 - val_new_score: 0.6115\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.9025 - acc: 0.7146 - new_score: 0.7164 - val_loss: 1.2769 - val_acc: 0.6397 - val_new_score: 0.6430\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.8013 - acc: 0.7489 - new_score: 0.7479 - val_loss: 1.4733 - val_acc: 0.6241 - val_new_score: 0.6371\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.7140 - acc: 0.7761 - new_score: 0.7802 - val_loss: 1.0474 - val_acc: 0.7186 - val_new_score: 0.7269\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.6487 - acc: 0.7946 - new_score: 0.7956 - val_loss: 0.9210 - val_acc: 0.7407 - val_new_score: 0.7464\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.5703 - acc: 0.8195 - new_score: 0.8212 - val_loss: 0.9353 - val_acc: 0.7477 - val_new_score: 0.7587\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.5183 - acc: 0.8420 - new_score: 0.8442 - val_loss: 0.7803 - val_acc: 0.7794 - val_new_score: 0.7890\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.4827 - acc: 0.8486 - new_score: 0.8544 - val_loss: 0.9592 - val_acc: 0.7633 - val_new_score: 0.7759\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.4793 - acc: 0.8562 - new_score: 0.8582 - val_loss: 0.7285 - val_acc: 0.8020 - val_new_score: 0.8076\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.4174 - acc: 0.8689 - new_score: 0.8720 - val_loss: 0.9670 - val_acc: 0.7598 - val_new_score: 0.7733\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.4209 - acc: 0.8736 - new_score: 0.8738 - val_loss: 0.8266 - val_acc: 0.7965 - val_new_score: 0.8025\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.3852 - acc: 0.8777 - new_score: 0.8816 - val_loss: 0.9564 - val_acc: 0.7658 - val_new_score: 0.7771\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.3727 - acc: 0.8806 - new_score: 0.8835 - val_loss: 0.8201 - val_acc: 0.7889 - val_new_score: 0.8002\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.3568 - acc: 0.8849 - new_score: 0.8882 - val_loss: 0.8536 - val_acc: 0.7784 - val_new_score: 0.7829\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.3265 - acc: 0.8930 - new_score: 0.8961 - val_loss: 0.7319 - val_acc: 0.8216 - val_new_score: 0.8270\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.3068 - acc: 0.9031 - new_score: 0.9065 - val_loss: 0.7987 - val_acc: 0.8000 - val_new_score: 0.8108\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.3058 - acc: 0.9001 - new_score: 0.9046 - val_loss: 0.6946 - val_acc: 0.8216 - val_new_score: 0.8289\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.2934 - acc: 0.9073 - new_score: 0.9107 - val_loss: 0.9170 - val_acc: 0.7940 - val_new_score: 0.8005\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.2824 - acc: 0.9099 - new_score: 0.9116 - val_loss: 1.1047 - val_acc: 0.7613 - val_new_score: 0.7628\n",
      "Epoch 28/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2821 - acc: 0.9135 - new_score: 0.9163 - val_loss: 0.6597 - val_acc: 0.8362 - val_new_score: 0.8436\n",
      "Epoch 29/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2594 - acc: 0.9171 - new_score: 0.9188 - val_loss: 0.9925 - val_acc: 0.7673 - val_new_score: 0.7736\n",
      "Epoch 30/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2620 - acc: 0.9187 - new_score: 0.9210 - val_loss: 0.6508 - val_acc: 0.8392 - val_new_score: 0.8452\n",
      "Epoch 31/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2573 - acc: 0.9204 - new_score: 0.9231 - val_loss: 0.8456 - val_acc: 0.7985 - val_new_score: 0.8044\n",
      "Epoch 32/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2431 - acc: 0.9260 - new_score: 0.9275 - val_loss: 0.7080 - val_acc: 0.8246 - val_new_score: 0.8332\n",
      "Epoch 33/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2354 - acc: 0.9260 - new_score: 0.9297 - val_loss: 0.7364 - val_acc: 0.8286 - val_new_score: 0.8350\n",
      "Epoch 34/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2262 - acc: 0.9310 - new_score: 0.9342 - val_loss: 0.8299 - val_acc: 0.8090 - val_new_score: 0.8159\n",
      "Epoch 35/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.2350 - acc: 0.9255 - new_score: 0.9283 - val_loss: 0.7881 - val_acc: 0.8085 - val_new_score: 0.8164\n",
      "Epoch 36/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2201 - acc: 0.9317 - new_score: 0.9348 - val_loss: 0.7546 - val_acc: 0.8256 - val_new_score: 0.8293\n",
      "Epoch 37/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.2082 - acc: 0.9360 - new_score: 0.9371 - val_loss: 0.8993 - val_acc: 0.7990 - val_new_score: 0.8059\n",
      "Epoch 38/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.2047 - acc: 0.9327 - new_score: 0.9375 - val_loss: 0.7623 - val_acc: 0.8296 - val_new_score: 0.8367\n",
      "Epoch 39/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2382 - acc: 0.9260 - new_score: 0.9295 - val_loss: 0.9010 - val_acc: 0.8131 - val_new_score: 0.8212\n",
      "Epoch 40/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2109 - acc: 0.9375 - new_score: 0.9405 - val_loss: 0.8322 - val_acc: 0.8080 - val_new_score: 0.8145\n",
      "Epoch 41/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2157 - acc: 0.9323 - new_score: 0.9352 - val_loss: 0.6214 - val_acc: 0.8503 - val_new_score: 0.8560\n",
      "Epoch 42/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1911 - acc: 0.9441 - new_score: 0.9461 - val_loss: 0.8707 - val_acc: 0.8146 - val_new_score: 0.8193\n",
      "Epoch 43/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1835 - acc: 0.9404 - new_score: 0.9418 - val_loss: 0.8979 - val_acc: 0.8090 - val_new_score: 0.8187\n",
      "Epoch 44/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1988 - acc: 0.9396 - new_score: 0.9420 - val_loss: 0.6527 - val_acc: 0.8467 - val_new_score: 0.8563\n",
      "Epoch 45/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1847 - acc: 0.9457 - new_score: 0.9461 - val_loss: 0.9035 - val_acc: 0.8035 - val_new_score: 0.8133\n",
      "Epoch 46/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1765 - acc: 0.9462 - new_score: 0.9485 - val_loss: 0.7813 - val_acc: 0.8372 - val_new_score: 0.8445\n",
      "Epoch 47/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1809 - acc: 0.9444 - new_score: 0.9472 - val_loss: 0.6435 - val_acc: 0.8628 - val_new_score: 0.8645\n",
      "Epoch 48/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1612 - acc: 0.9533 - new_score: 0.9554 - val_loss: 0.7097 - val_acc: 0.8402 - val_new_score: 0.8447\n",
      "Epoch 49/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1595 - acc: 0.9496 - new_score: 0.9515 - val_loss: 0.7185 - val_acc: 0.8397 - val_new_score: 0.8478\n",
      "Epoch 50/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1673 - acc: 0.9485 - new_score: 0.9497 - val_loss: 0.6350 - val_acc: 0.8638 - val_new_score: 0.8710\n",
      "Epoch 51/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1679 - acc: 0.9475 - new_score: 0.9495 - val_loss: 0.6445 - val_acc: 0.8523 - val_new_score: 0.8549\n",
      "Epoch 52/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1555 - acc: 0.9506 - new_score: 0.9538 - val_loss: 0.6133 - val_acc: 0.8683 - val_new_score: 0.8720\n",
      "Epoch 53/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1615 - acc: 0.9507 - new_score: 0.9520 - val_loss: 0.6064 - val_acc: 0.8709 - val_new_score: 0.8781\n",
      "Epoch 54/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1667 - acc: 0.9491 - new_score: 0.9518 - val_loss: 0.7073 - val_acc: 0.8447 - val_new_score: 0.8505\n",
      "Epoch 55/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1605 - acc: 0.9479 - new_score: 0.9502 - val_loss: 0.7487 - val_acc: 0.8422 - val_new_score: 0.8511\n",
      "Epoch 56/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1760 - acc: 0.9455 - new_score: 0.9485 - val_loss: 0.7040 - val_acc: 0.8367 - val_new_score: 0.8447\n",
      "Epoch 57/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1323 - acc: 0.9580 - new_score: 0.9606 - val_loss: 0.7098 - val_acc: 0.8513 - val_new_score: 0.8606\n",
      "Epoch 58/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1661 - acc: 0.9485 - new_score: 0.9506 - val_loss: 0.7359 - val_acc: 0.8302 - val_new_score: 0.8374\n",
      "Epoch 59/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1465 - acc: 0.9550 - new_score: 0.9572 - val_loss: 0.7329 - val_acc: 0.8472 - val_new_score: 0.8525\n",
      "Epoch 60/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1406 - acc: 0.9575 - new_score: 0.9589 - val_loss: 0.7569 - val_acc: 0.8442 - val_new_score: 0.8520\n",
      "Epoch 61/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1440 - acc: 0.9567 - new_score: 0.9580 - val_loss: 0.8650 - val_acc: 0.8216 - val_new_score: 0.8263\n",
      "Epoch 62/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1286 - acc: 0.9614 - new_score: 0.9621 - val_loss: 0.6850 - val_acc: 0.8583 - val_new_score: 0.8629\n",
      "Epoch 63/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1506 - acc: 0.9570 - new_score: 0.9590 - val_loss: 0.8282 - val_acc: 0.8357 - val_new_score: 0.8424\n",
      "Epoch 64/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1328 - acc: 0.9570 - new_score: 0.9585 - val_loss: 0.7273 - val_acc: 0.8538 - val_new_score: 0.8585\n",
      "Epoch 65/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1429 - acc: 0.9553 - new_score: 0.9578 - val_loss: 0.5800 - val_acc: 0.8603 - val_new_score: 0.8655\n",
      "Epoch 66/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1366 - acc: 0.9577 - new_score: 0.9601 - val_loss: 0.7169 - val_acc: 0.8608 - val_new_score: 0.8635\n",
      "Epoch 67/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1345 - acc: 0.9626 - new_score: 0.9643 - val_loss: 0.7420 - val_acc: 0.8447 - val_new_score: 0.8517\n",
      "Epoch 68/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1331 - acc: 0.9604 - new_score: 0.9617 - val_loss: 0.9020 - val_acc: 0.8085 - val_new_score: 0.8140\n",
      "Epoch 69/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1341 - acc: 0.9607 - new_score: 0.9621 - val_loss: 0.5695 - val_acc: 0.8749 - val_new_score: 0.8796\n",
      "Epoch 70/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1349 - acc: 0.9609 - new_score: 0.9626 - val_loss: 0.7436 - val_acc: 0.8472 - val_new_score: 0.8529\n",
      "Epoch 71/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1406 - acc: 0.9553 - new_score: 0.9563 - val_loss: 0.5931 - val_acc: 0.8683 - val_new_score: 0.8743\n",
      "Epoch 72/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1383 - acc: 0.9586 - new_score: 0.9607 - val_loss: 0.7323 - val_acc: 0.8432 - val_new_score: 0.8499\n",
      "Epoch 73/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1162 - acc: 0.9647 - new_score: 0.9670 - val_loss: 0.6817 - val_acc: 0.8603 - val_new_score: 0.8652\n",
      "Epoch 74/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1115 - acc: 0.9674 - new_score: 0.9685 - val_loss: 0.6308 - val_acc: 0.8663 - val_new_score: 0.8702\n",
      "Epoch 75/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1235 - acc: 0.9627 - new_score: 0.9639 - val_loss: 0.7268 - val_acc: 0.8422 - val_new_score: 0.8476\n",
      "Epoch 76/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1314 - acc: 0.9615 - new_score: 0.9632 - val_loss: 0.8071 - val_acc: 0.8372 - val_new_score: 0.8400\n",
      "Epoch 77/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1372 - acc: 0.9582 - new_score: 0.9585 - val_loss: 0.5957 - val_acc: 0.8693 - val_new_score: 0.8744\n",
      "Epoch 78/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1213 - acc: 0.9624 - new_score: 0.9646 - val_loss: 0.7473 - val_acc: 0.8518 - val_new_score: 0.8605\n",
      "Epoch 79/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1166 - acc: 0.9670 - new_score: 0.9673 - val_loss: 0.5774 - val_acc: 0.8719 - val_new_score: 0.8800\n",
      "Epoch 80/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1146 - acc: 0.9656 - new_score: 0.9669 - val_loss: 0.6663 - val_acc: 0.8719 - val_new_score: 0.8765\n",
      "Epoch 81/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1224 - acc: 0.9637 - new_score: 0.9650 - val_loss: 0.8607 - val_acc: 0.8357 - val_new_score: 0.8433\n",
      "Epoch 82/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1126 - acc: 0.9650 - new_score: 0.9657 - val_loss: 0.7615 - val_acc: 0.8538 - val_new_score: 0.8572\n",
      "Epoch 83/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1170 - acc: 0.9641 - new_score: 0.9657 - val_loss: 0.6616 - val_acc: 0.8618 - val_new_score: 0.8655\n",
      "Epoch 84/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1045 - acc: 0.9665 - new_score: 0.9682 - val_loss: 0.8289 - val_acc: 0.8477 - val_new_score: 0.8508\n",
      "Epoch 85/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1173 - acc: 0.9652 - new_score: 0.9663 - val_loss: 0.6641 - val_acc: 0.8628 - val_new_score: 0.8644\n",
      "Epoch 86/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1109 - acc: 0.9651 - new_score: 0.9665 - val_loss: 0.7351 - val_acc: 0.8593 - val_new_score: 0.8634\n",
      "Epoch 87/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0999 - acc: 0.9698 - new_score: 0.9711 - val_loss: 0.8172 - val_acc: 0.8482 - val_new_score: 0.8530\n",
      "Epoch 88/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1156 - acc: 0.9646 - new_score: 0.9661 - val_loss: 0.6413 - val_acc: 0.8709 - val_new_score: 0.8773\n",
      "Epoch 89/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0967 - acc: 0.9694 - new_score: 0.9704 - val_loss: 0.8079 - val_acc: 0.8503 - val_new_score: 0.8568\n",
      "Epoch 90/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1056 - acc: 0.9691 - new_score: 0.9689 - val_loss: 0.8731 - val_acc: 0.8337 - val_new_score: 0.8405\n",
      "Epoch 91/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1155 - acc: 0.9665 - new_score: 0.9678 - val_loss: 0.6641 - val_acc: 0.8633 - val_new_score: 0.8708\n",
      "Epoch 92/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1084 - acc: 0.9676 - new_score: 0.9693 - val_loss: 0.6382 - val_acc: 0.8668 - val_new_score: 0.8735\n",
      "Epoch 93/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0892 - acc: 0.9729 - new_score: 0.9745 - val_loss: 0.7321 - val_acc: 0.8598 - val_new_score: 0.8645\n",
      "Epoch 94/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0997 - acc: 0.9688 - new_score: 0.9701 - val_loss: 0.7012 - val_acc: 0.8658 - val_new_score: 0.8709\n",
      "Epoch 95/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1153 - acc: 0.9635 - new_score: 0.9652 - val_loss: 0.7884 - val_acc: 0.8437 - val_new_score: 0.8484\n",
      "Epoch 96/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1001 - acc: 0.9659 - new_score: 0.9673 - val_loss: 0.6695 - val_acc: 0.8789 - val_new_score: 0.8828\n",
      "Epoch 97/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0964 - acc: 0.9705 - new_score: 0.9720 - val_loss: 0.6439 - val_acc: 0.8754 - val_new_score: 0.8803\n",
      "Epoch 98/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1057 - acc: 0.9684 - new_score: 0.9693 - val_loss: 0.6182 - val_acc: 0.8724 - val_new_score: 0.8767\n",
      "Epoch 99/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0950 - acc: 0.9702 - new_score: 0.9719 - val_loss: 0.9496 - val_acc: 0.8387 - val_new_score: 0.8395\n",
      "Epoch 100/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1063 - acc: 0.9674 - new_score: 0.9692 - val_loss: 0.7183 - val_acc: 0.8658 - val_new_score: 0.8693\n",
      "Epoch 101/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1057 - acc: 0.9696 - new_score: 0.9708 - val_loss: 0.6597 - val_acc: 0.8714 - val_new_score: 0.8763\n",
      "Epoch 102/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0869 - acc: 0.9740 - new_score: 0.9746 - val_loss: 0.7356 - val_acc: 0.8658 - val_new_score: 0.8703\n",
      "Epoch 103/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1034 - acc: 0.9709 - new_score: 0.9722 - val_loss: 0.6404 - val_acc: 0.8709 - val_new_score: 0.8757\n",
      "Epoch 104/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0915 - acc: 0.9729 - new_score: 0.9741 - val_loss: 0.7143 - val_acc: 0.8749 - val_new_score: 0.8797\n",
      "Epoch 105/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0878 - acc: 0.9749 - new_score: 0.9768 - val_loss: 0.6657 - val_acc: 0.8724 - val_new_score: 0.8779\n",
      "Epoch 106/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0816 - acc: 0.9756 - new_score: 0.9762 - val_loss: 0.8017 - val_acc: 0.8487 - val_new_score: 0.8560\n",
      "Epoch 107/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1011 - acc: 0.9686 - new_score: 0.9707 - val_loss: 0.7825 - val_acc: 0.8538 - val_new_score: 0.8591\n",
      "Epoch 108/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0880 - acc: 0.9744 - new_score: 0.9755 - val_loss: 0.8844 - val_acc: 0.8447 - val_new_score: 0.8515\n",
      "Epoch 109/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1091 - acc: 0.9661 - new_score: 0.9683 - val_loss: 0.8468 - val_acc: 0.8492 - val_new_score: 0.8570\n",
      "Epoch 110/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0822 - acc: 0.9731 - new_score: 0.9736 - val_loss: 0.9041 - val_acc: 0.8312 - val_new_score: 0.8377\n",
      "Epoch 111/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0913 - acc: 0.9712 - new_score: 0.9725 - val_loss: 0.7641 - val_acc: 0.8633 - val_new_score: 0.8696\n",
      "Epoch 112/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0975 - acc: 0.9730 - new_score: 0.9735 - val_loss: 0.6630 - val_acc: 0.8744 - val_new_score: 0.8777\n",
      "Epoch 113/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0846 - acc: 0.9744 - new_score: 0.9752 - val_loss: 0.6661 - val_acc: 0.8784 - val_new_score: 0.8839\n",
      "Epoch 114/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0755 - acc: 0.9791 - new_score: 0.9798 - val_loss: 0.7431 - val_acc: 0.8663 - val_new_score: 0.8732\n",
      "Epoch 115/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0941 - acc: 0.9728 - new_score: 0.9742 - val_loss: 0.7979 - val_acc: 0.8578 - val_new_score: 0.8597\n",
      "Epoch 116/500\n",
      " 54/250 [=====>........................] - ETA: 1:16 - loss: 0.0769 - acc: 0.9763 - new_score: 0.9773"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6d4a58b46876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m hist = model.fit_generator( train_generator, initial_epoch=0, epochs = 500, validation_data=val_generator, \n\u001b[1;32m      3\u001b[0m                            \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                            steps_per_epoch=len(x_train)/batch_size, validation_steps=len(x_val)/batch_size)\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# epochs = 100\n",
    "hist = model.fit_generator( train_generator, initial_epoch=0, epochs = 500, validation_data=val_generator, \n",
    "                           callbacks=[tensorboard, cp_callback, es_callback],\n",
    "                           steps_per_epoch=len(x_train)/batch_size, validation_steps=len(x_val)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8398368277549744, 0.8225, 0.8272113695144653]\n"
     ]
    }
   ],
   "source": [
    "# hist = model.evaluate( x_val/255., y_val_onehot, batch_size=30, verbose=1 )\n",
    "hist = model.evaluate_generator(val_generator, steps=len(x_val)/batch_size)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('car-v4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data load for submission\n",
    "x_test = np.load('x_test.npy')\n",
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one model submission \n",
    "if False:\n",
    "    predictions = model.predict( x_test )\n",
    "    pdi = np.argmax(predictions, axis=1)\n",
    "    print(pdi, np.min(pdi), np.max(pdi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 : car-v4-1.ckpt\n",
      "prediction 1 : [[3.69458289e-14 1.11258962e-35 1.77841311e-30 ... 2.23007878e-13\n",
      "  1.40615340e-23 1.00434986e-23]\n",
      " [1.16716154e-20 3.41513017e-16 4.37719437e-15 ... 3.59256451e-18\n",
      "  5.38302753e-14 2.45638759e-10]\n",
      " [1.83429156e-23 4.70149961e-23 1.99139752e-19 ... 1.70155275e-27\n",
      "  7.28396137e-24 1.46811952e-17]\n",
      " ...\n",
      " [2.84027674e-27 2.25980703e-19 1.54869200e-19 ... 3.77228287e-20\n",
      "  6.34357586e-16 3.66114781e-28]\n",
      " [2.74565703e-16 3.95558224e-18 1.68523005e-18 ... 7.69631783e-20\n",
      "  1.92088345e-09 1.56790845e-12]\n",
      " [2.12169606e-22 1.42689730e-15 6.09978214e-12 ... 5.84064686e-24\n",
      "  1.16103016e-09 1.41565775e-23]]\n",
      "model 2 : car-v4-2.ckpt\n",
      "prediction 2 : [[3.43239437e-09 3.34558650e-36 7.07518992e-26 ... 6.44292454e-13\n",
      "  4.49355019e-23 7.84796395e-20]\n",
      " [9.17424760e-17 1.76205610e-20 1.21798364e-18 ... 3.95197028e-25\n",
      "  3.62783404e-24 1.63518965e-13]\n",
      " [7.78969576e-25 1.23197044e-29 2.47368342e-30 ... 2.27081043e-23\n",
      "  6.36523828e-25 5.76079336e-16]\n",
      " ...\n",
      " [2.27793794e-28 5.88929170e-17 2.78877802e-18 ... 9.08388287e-15\n",
      "  1.57846823e-17 1.65419992e-19]\n",
      " [6.70884876e-21 1.72441583e-20 9.58646617e-23 ... 4.93591097e-24\n",
      "  1.47381054e-15 1.26556880e-17]\n",
      " [1.35982095e-20 1.99068572e-13 1.14258872e-19 ... 1.11795237e-20\n",
      "  2.36618098e-13 6.30829566e-18]]\n",
      "model 3 : car-v4-3.ckpt\n",
      "prediction 3 : [[3.27942362e-09 1.91050811e-24 1.79848318e-18 ... 7.78207997e-14\n",
      "  2.22346710e-10 1.02893476e-13]\n",
      " [7.03348185e-20 1.79037802e-19 8.19317765e-17 ... 2.20385917e-18\n",
      "  9.71759904e-14 2.75180767e-10]\n",
      " [0.00000000e+00 3.67614937e-35 7.95140962e-37 ... 9.70227823e-32\n",
      "  4.75000453e-26 7.81907777e-18]\n",
      " ...\n",
      " [5.21365540e-34 2.66763880e-22 1.68079216e-28 ... 4.90141591e-21\n",
      "  1.08289432e-19 6.25466852e-30]\n",
      " [3.25018735e-36 4.37356729e-23 2.36808821e-25 ... 3.94064791e-25\n",
      "  1.91134594e-14 1.00785689e-20]\n",
      " [6.24616798e-19 1.33426201e-10 6.01604676e-14 ... 3.17636425e-18\n",
      "  5.19532402e-14 2.12080702e-15]]\n",
      "model 4 : car-v4-4.ckpt\n",
      "prediction 4 : [[3.7954728e-10 2.7760231e-32 3.0201012e-31 ... 2.7008211e-20\n",
      "  5.3362128e-30 1.5124733e-17]\n",
      " [2.9380928e-28 1.6598612e-22 5.1872671e-22 ... 1.0684927e-26\n",
      "  3.4549269e-28 7.4070605e-13]\n",
      " [4.1991787e-18 0.0000000e+00 3.2300244e-36 ... 1.8308170e-16\n",
      "  1.0430449e-23 4.4075504e-13]\n",
      " ...\n",
      " [3.5617091e-31 9.2904750e-21 4.0326239e-22 ... 8.4773935e-20\n",
      "  4.1716308e-22 2.2502847e-33]\n",
      " [6.5438164e-23 3.2031571e-26 8.9853266e-26 ... 1.1130640e-15\n",
      "  2.7135773e-08 3.3961774e-11]\n",
      " [4.9776511e-14 6.0390386e-14 1.2456694e-15 ... 8.8770630e-13\n",
      "  9.6268229e-07 1.3889755e-17]]\n",
      "model 5 : car-v4-5.ckpt\n",
      "prediction 5 : [[8.87866576e-14 7.42460727e-28 2.63500984e-23 ... 8.59177348e-17\n",
      "  1.84427087e-21 1.86671083e-26]\n",
      " [7.64670467e-38 0.00000000e+00 1.05032051e-37 ... 1.11903665e-31\n",
      "  1.48924946e-25 4.02179341e-14]\n",
      " [0.00000000e+00 1.16652063e-31 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 2.21839425e-37]\n",
      " ...\n",
      " [1.18793815e-33 1.52867307e-20 7.51389139e-21 ... 1.49432558e-22\n",
      "  2.15967014e-18 1.00965463e-29]\n",
      " [2.17675058e-31 3.91848274e-24 3.41549359e-24 ... 5.82352104e-27\n",
      "  1.18391641e-09 2.58644449e-16]\n",
      " [3.65972335e-24 1.45638930e-14 3.05785473e-20 ... 1.13549383e-19\n",
      "  4.45808200e-06 7.65687013e-18]]\n",
      "final: [123  97 156 ...  43  49  93] 0 195\n"
     ]
    }
   ],
   "source": [
    "# ensamble. submission.\n",
    "# model = load_mode('car-v4.h5')\n",
    "if True:\n",
    "#     mo = load_model(mp, custom_objects={'new_score': new_score})\n",
    "    inputs = Input(shape=(224,224,3))\n",
    "    net = xception.Xception(input_tensor=inputs, input_shape=(224, 224, 3), include_top=False, pooling='max')\n",
    "    net2 = Dense(224, activation='relu') (net.layers[-1].output)\n",
    "    net2 = Dense(196)(net2)\n",
    "    net2 = Softmax(196)(net2)\n",
    "    model = Model(inputs=inputs, outputs=net2)\n",
    "    predictions=[]\n",
    "    for ff in range(1, fold_k+1):\n",
    "        mp='car-v4-'+str(ff)+'.ckpt'\n",
    "        print('model',ff,':', mp)\n",
    "        model.load_weights(mp)\n",
    "        pr = model.predict( x_test )\n",
    "        predictions.append(pr)\n",
    "        print('prediction',ff,':',pr)\n",
    "    predictions = np.asarray(predictions)\n",
    "    prk = np.sum(predictions, axis=0 )\n",
    "    pdi = np.argmax(prk, axis=1)\n",
    "    print('final:', pdi, np.min(pdi), np.max(pdi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_file</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_00001.jpg</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_00002.jpg</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_00003.jpg</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_00004.jpg</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_00005.jpg</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         img_file  class\n",
       "0  test_00001.jpg    124\n",
       "1  test_00002.jpg     98\n",
       "2  test_00003.jpg    157\n",
       "3  test_00004.jpg     94\n",
       "4  test_00005.jpg     18"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(basedir+'sample_submission.csv')\n",
    "submission[\"class\"] = pdi + 1  # class [0,195] to [1,196]  \n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f521c696a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(submission[\"class\"], order=submission[\"class\"].value_counts(ascending=True).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
