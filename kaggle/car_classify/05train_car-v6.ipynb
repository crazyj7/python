{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train car - v6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data ; crop and resize ; add margin!\n",
    "network ; xception \n",
    "\n",
    "ImageAugment  ; shift add. \n",
    "# random_eraser ; image part remove ; off\n",
    "\n",
    "batch 32\n",
    "earlystop ; f1_score \n",
    "checkpoint best save \n",
    "\n",
    "train acc;  , val acc;  , lb acc;   \n",
    "model1 ;  \n",
    "model2;  \n",
    "model3 ; \n",
    "\n",
    "enssamble. sum.\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications import xception\n",
    "from keras.preprocessing import image\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dropout, MaxPooling2D, Flatten, Dense, Softmax\n",
    "import random\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, K\n",
    "from keras.models import Input, Model\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache=False\n",
    "basedir = './'\n",
    "imgwidth=224\n",
    "imgheight=224\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# K fold\n",
    "fold_k = 5\n",
    "# current fold\n",
    "fold_c = 5   # 1~fold_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainall = np.load('x_train.npy')\n",
    "y_trainall = np.load('y_train.npy')\n",
    "dfclass = pd.read_csv(basedir+'class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelpath= car-v4-5.ckpt\n",
      "(8000, 224, 224, 3) (8000,) (1990, 224, 224, 3) (1990,)\n",
      "0 195\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "datacnt = x_trainall.shape[0]\n",
    "flagval = np.zeros(datacnt)\n",
    "modelpath = 'car-v4-'+str(fold_c)+'.ckpt'\n",
    "\n",
    "print('modelpath=', modelpath)\n",
    "flagval[(fold_c-1)*2000:(fold_c)*2000] = 1\n",
    "\n",
    "x_train = x_trainall[flagval==0]\n",
    "y_train = y_trainall[flagval==0]\n",
    "x_val = x_trainall[flagval==1]\n",
    "y_val = y_trainall[flagval==1]\n",
    "    \n",
    "del x_trainall\n",
    "del y_trainall\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n",
    "print(np.min(y_train), np.max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_onehot = np_utils.to_categorical(y_train, 196)\n",
    "y_val_onehot = np_utils.to_categorical(y_val, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://github.com/yu4u/cutout-random-erasing/blob/master/cifar10_resnet.py\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "        return input_img\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augumentation\n",
    "batch_size=32  # 32, 64\n",
    "# datagen1 = ImageDataGenerator(rescale=1./255, shear_range=0.1, zoom_range=0.1, horizontal_flip=True, vertical_flip=False, \n",
    "#                               width_shift_range=0.1, height_shift_range=0.1,\n",
    "#                               fill_mode='nearest', preprocessing_function = get_random_eraser(v_l=0, v_h=1),)\n",
    "datagen1 = ImageDataGenerator(rescale=1./255, shear_range=0.1, zoom_range=0.1, horizontal_flip=True, vertical_flip=False, \n",
    "                              width_shift_range=0.1, height_shift_range=0.1,\n",
    "                              fill_mode='nearest')\n",
    "datagen2 = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = datagen1.flow(x_train, y_train_onehot, batch_size=batch_size)\n",
    "val_generator = datagen2.flow(x_val, y_val_onehot, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score \n",
    "def new_score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = (true_positives + K.epsilon()) / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = (true_positives + K.epsilon()) / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### checkpoint save weights in progress...\n",
    "cp_callback = ModelCheckpoint(modelpath,  monitor='val_new_score', mode='max', save_best_only=True, save_weights_only=True)\n",
    "es_callback = EarlyStopping(monitor='val_new_score',  mode='max', patience=20, min_delta=0.0001)\n",
    "\n",
    "# tensorboard log\n",
    "if not os.path.exists('log'):\n",
    "    os.mkdir('log')\n",
    "tensorboard = TensorBoard(log_dir='log/'+str(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/psychic/.conda/envs/tensorgpu36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(224,224,3))\n",
    "net = xception.Xception(input_tensor=inputs, input_shape=(224, 224, 3), include_top=False, weights='imagenet', pooling='max')\n",
    "net2 = Dense(224, activation='relu') (net.layers[-1].output)\n",
    "net2 = Dense(196)(net2)\n",
    "net2 = Softmax(196)(net2)\n",
    "model = Model(inputs=inputs, outputs=net2)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no freezing...\n"
     ]
    }
   ],
   "source": [
    "##### model freeze. after acc 90.\n",
    "if False:\n",
    "    print('freezing...')\n",
    "    for layer in model.layers[:-4]:\n",
    "        layer.trainable=False\n",
    "else:\n",
    "    print('no freezing...')\n",
    "#     for layer in model.layers:\n",
    "#         print(layer, layer.trainable)\n",
    "#     model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', new_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(modelpath):\n",
    "    print('load weights...')\n",
    "    model.load_weights(modelpath)\n",
    "else:\n",
    "    print('not found weights... new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/psychic/.conda/envs/tensorgpu36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/psychic/.conda/envs/tensorgpu36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/500\n",
      "250/250 [==============================] - 109s 437ms/step - loss: 5.1234 - acc: 0.0106 - new_score: 6.2500e-09 - val_loss: 5.2796 - val_acc: 0.0121 - val_new_score: 6.1276e-09\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 103s 410ms/step - loss: 4.4498 - acc: 0.0411 - new_score: 4.8485e-04 - val_loss: 5.0951 - val_acc: 0.0382 - val_new_score: 0.0057\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 103s 410ms/step - loss: 3.7394 - acc: 0.0983 - new_score: 0.0110 - val_loss: 3.9467 - val_acc: 0.0874 - val_new_score: 0.0200\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 103s 411ms/step - loss: 3.0210 - acc: 0.1862 - new_score: 0.0553 - val_loss: 2.8290 - val_acc: 0.2236 - val_new_score: 0.1226\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 2.4196 - acc: 0.3166 - new_score: 0.1881 - val_loss: 2.9334 - val_acc: 0.2427 - val_new_score: 0.2056\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 1.8964 - acc: 0.4409 - new_score: 0.3620 - val_loss: 1.6958 - val_acc: 0.5070 - val_new_score: 0.4717\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 1.5408 - acc: 0.5260 - new_score: 0.4939 - val_loss: 1.7307 - val_acc: 0.4950 - val_new_score: 0.4735\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 1.2768 - acc: 0.6079 - new_score: 0.5819 - val_loss: 1.2141 - val_acc: 0.6432 - val_new_score: 0.6370\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 1.0443 - acc: 0.6715 - new_score: 0.6646 - val_loss: 1.4062 - val_acc: 0.6141 - val_new_score: 0.6115\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.9025 - acc: 0.7146 - new_score: 0.7164 - val_loss: 1.2769 - val_acc: 0.6397 - val_new_score: 0.6430\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.8013 - acc: 0.7489 - new_score: 0.7479 - val_loss: 1.4733 - val_acc: 0.6241 - val_new_score: 0.6371\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.7140 - acc: 0.7761 - new_score: 0.7802 - val_loss: 1.0474 - val_acc: 0.7186 - val_new_score: 0.7269\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.6487 - acc: 0.7946 - new_score: 0.7956 - val_loss: 0.9210 - val_acc: 0.7407 - val_new_score: 0.7464\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.5703 - acc: 0.8195 - new_score: 0.8212 - val_loss: 0.9353 - val_acc: 0.7477 - val_new_score: 0.7587\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.5183 - acc: 0.8420 - new_score: 0.8442 - val_loss: 0.7803 - val_acc: 0.7794 - val_new_score: 0.7890\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.4827 - acc: 0.8486 - new_score: 0.8544 - val_loss: 0.9592 - val_acc: 0.7633 - val_new_score: 0.7759\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.4793 - acc: 0.8562 - new_score: 0.8582 - val_loss: 0.7285 - val_acc: 0.8020 - val_new_score: 0.8076\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.4174 - acc: 0.8689 - new_score: 0.8720 - val_loss: 0.9670 - val_acc: 0.7598 - val_new_score: 0.7733\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.4209 - acc: 0.8736 - new_score: 0.8738 - val_loss: 0.8266 - val_acc: 0.7965 - val_new_score: 0.8025\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.3852 - acc: 0.8777 - new_score: 0.8816 - val_loss: 0.9564 - val_acc: 0.7658 - val_new_score: 0.7771\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.3727 - acc: 0.8806 - new_score: 0.8835 - val_loss: 0.8201 - val_acc: 0.7889 - val_new_score: 0.8002\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.3568 - acc: 0.8849 - new_score: 0.8882 - val_loss: 0.8536 - val_acc: 0.7784 - val_new_score: 0.7829\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.3265 - acc: 0.8930 - new_score: 0.8961 - val_loss: 0.7319 - val_acc: 0.8216 - val_new_score: 0.8270\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.3068 - acc: 0.9031 - new_score: 0.9065 - val_loss: 0.7987 - val_acc: 0.8000 - val_new_score: 0.8108\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.3058 - acc: 0.9001 - new_score: 0.9046 - val_loss: 0.6946 - val_acc: 0.8216 - val_new_score: 0.8289\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.2934 - acc: 0.9073 - new_score: 0.9107 - val_loss: 0.9170 - val_acc: 0.7940 - val_new_score: 0.8005\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.2824 - acc: 0.9099 - new_score: 0.9116 - val_loss: 1.1047 - val_acc: 0.7613 - val_new_score: 0.7628\n",
      "Epoch 28/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2821 - acc: 0.9135 - new_score: 0.9163 - val_loss: 0.6597 - val_acc: 0.8362 - val_new_score: 0.8436\n",
      "Epoch 29/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2594 - acc: 0.9171 - new_score: 0.9188 - val_loss: 0.9925 - val_acc: 0.7673 - val_new_score: 0.7736\n",
      "Epoch 30/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2620 - acc: 0.9187 - new_score: 0.9210 - val_loss: 0.6508 - val_acc: 0.8392 - val_new_score: 0.8452\n",
      "Epoch 31/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2573 - acc: 0.9204 - new_score: 0.9231 - val_loss: 0.8456 - val_acc: 0.7985 - val_new_score: 0.8044\n",
      "Epoch 32/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2431 - acc: 0.9260 - new_score: 0.9275 - val_loss: 0.7080 - val_acc: 0.8246 - val_new_score: 0.8332\n",
      "Epoch 33/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2354 - acc: 0.9260 - new_score: 0.9297 - val_loss: 0.7364 - val_acc: 0.8286 - val_new_score: 0.8350\n",
      "Epoch 34/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2262 - acc: 0.9310 - new_score: 0.9342 - val_loss: 0.8299 - val_acc: 0.8090 - val_new_score: 0.8159\n",
      "Epoch 35/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.2350 - acc: 0.9255 - new_score: 0.9283 - val_loss: 0.7881 - val_acc: 0.8085 - val_new_score: 0.8164\n",
      "Epoch 36/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2201 - acc: 0.9317 - new_score: 0.9348 - val_loss: 0.7546 - val_acc: 0.8256 - val_new_score: 0.8293\n",
      "Epoch 37/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.2082 - acc: 0.9360 - new_score: 0.9371 - val_loss: 0.8993 - val_acc: 0.7990 - val_new_score: 0.8059\n",
      "Epoch 38/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.2047 - acc: 0.9327 - new_score: 0.9375 - val_loss: 0.7623 - val_acc: 0.8296 - val_new_score: 0.8367\n",
      "Epoch 39/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2382 - acc: 0.9260 - new_score: 0.9295 - val_loss: 0.9010 - val_acc: 0.8131 - val_new_score: 0.8212\n",
      "Epoch 40/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2109 - acc: 0.9375 - new_score: 0.9405 - val_loss: 0.8322 - val_acc: 0.8080 - val_new_score: 0.8145\n",
      "Epoch 41/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.2157 - acc: 0.9323 - new_score: 0.9352 - val_loss: 0.6214 - val_acc: 0.8503 - val_new_score: 0.8560\n",
      "Epoch 42/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1911 - acc: 0.9441 - new_score: 0.9461 - val_loss: 0.8707 - val_acc: 0.8146 - val_new_score: 0.8193\n",
      "Epoch 43/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1835 - acc: 0.9404 - new_score: 0.9418 - val_loss: 0.8979 - val_acc: 0.8090 - val_new_score: 0.8187\n",
      "Epoch 44/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1988 - acc: 0.9396 - new_score: 0.9420 - val_loss: 0.6527 - val_acc: 0.8467 - val_new_score: 0.8563\n",
      "Epoch 45/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1847 - acc: 0.9457 - new_score: 0.9461 - val_loss: 0.9035 - val_acc: 0.8035 - val_new_score: 0.8133\n",
      "Epoch 46/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1765 - acc: 0.9462 - new_score: 0.9485 - val_loss: 0.7813 - val_acc: 0.8372 - val_new_score: 0.8445\n",
      "Epoch 47/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1809 - acc: 0.9444 - new_score: 0.9472 - val_loss: 0.6435 - val_acc: 0.8628 - val_new_score: 0.8645\n",
      "Epoch 48/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1612 - acc: 0.9533 - new_score: 0.9554 - val_loss: 0.7097 - val_acc: 0.8402 - val_new_score: 0.8447\n",
      "Epoch 49/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1595 - acc: 0.9496 - new_score: 0.9515 - val_loss: 0.7185 - val_acc: 0.8397 - val_new_score: 0.8478\n",
      "Epoch 50/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1673 - acc: 0.9485 - new_score: 0.9497 - val_loss: 0.6350 - val_acc: 0.8638 - val_new_score: 0.8710\n",
      "Epoch 51/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1679 - acc: 0.9475 - new_score: 0.9495 - val_loss: 0.6445 - val_acc: 0.8523 - val_new_score: 0.8549\n",
      "Epoch 52/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1555 - acc: 0.9506 - new_score: 0.9538 - val_loss: 0.6133 - val_acc: 0.8683 - val_new_score: 0.8720\n",
      "Epoch 53/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1615 - acc: 0.9507 - new_score: 0.9520 - val_loss: 0.6064 - val_acc: 0.8709 - val_new_score: 0.8781\n",
      "Epoch 54/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1667 - acc: 0.9491 - new_score: 0.9518 - val_loss: 0.7073 - val_acc: 0.8447 - val_new_score: 0.8505\n",
      "Epoch 55/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1605 - acc: 0.9479 - new_score: 0.9502 - val_loss: 0.7487 - val_acc: 0.8422 - val_new_score: 0.8511\n",
      "Epoch 56/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1760 - acc: 0.9455 - new_score: 0.9485 - val_loss: 0.7040 - val_acc: 0.8367 - val_new_score: 0.8447\n",
      "Epoch 57/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1323 - acc: 0.9580 - new_score: 0.9606 - val_loss: 0.7098 - val_acc: 0.8513 - val_new_score: 0.8606\n",
      "Epoch 58/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1661 - acc: 0.9485 - new_score: 0.9506 - val_loss: 0.7359 - val_acc: 0.8302 - val_new_score: 0.8374\n",
      "Epoch 59/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1465 - acc: 0.9550 - new_score: 0.9572 - val_loss: 0.7329 - val_acc: 0.8472 - val_new_score: 0.8525\n",
      "Epoch 60/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1406 - acc: 0.9575 - new_score: 0.9589 - val_loss: 0.7569 - val_acc: 0.8442 - val_new_score: 0.8520\n",
      "Epoch 61/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1440 - acc: 0.9567 - new_score: 0.9580 - val_loss: 0.8650 - val_acc: 0.8216 - val_new_score: 0.8263\n",
      "Epoch 62/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1286 - acc: 0.9614 - new_score: 0.9621 - val_loss: 0.6850 - val_acc: 0.8583 - val_new_score: 0.8629\n",
      "Epoch 63/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1506 - acc: 0.9570 - new_score: 0.9590 - val_loss: 0.8282 - val_acc: 0.8357 - val_new_score: 0.8424\n",
      "Epoch 64/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1328 - acc: 0.9570 - new_score: 0.9585 - val_loss: 0.7273 - val_acc: 0.8538 - val_new_score: 0.8585\n",
      "Epoch 65/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1429 - acc: 0.9553 - new_score: 0.9578 - val_loss: 0.5800 - val_acc: 0.8603 - val_new_score: 0.8655\n",
      "Epoch 66/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1366 - acc: 0.9577 - new_score: 0.9601 - val_loss: 0.7169 - val_acc: 0.8608 - val_new_score: 0.8635\n",
      "Epoch 67/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1345 - acc: 0.9626 - new_score: 0.9643 - val_loss: 0.7420 - val_acc: 0.8447 - val_new_score: 0.8517\n",
      "Epoch 68/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1331 - acc: 0.9604 - new_score: 0.9617 - val_loss: 0.9020 - val_acc: 0.8085 - val_new_score: 0.8140\n",
      "Epoch 69/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1341 - acc: 0.9607 - new_score: 0.9621 - val_loss: 0.5695 - val_acc: 0.8749 - val_new_score: 0.8796\n",
      "Epoch 70/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1349 - acc: 0.9609 - new_score: 0.9626 - val_loss: 0.7436 - val_acc: 0.8472 - val_new_score: 0.8529\n",
      "Epoch 71/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1406 - acc: 0.9553 - new_score: 0.9563 - val_loss: 0.5931 - val_acc: 0.8683 - val_new_score: 0.8743\n",
      "Epoch 72/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1383 - acc: 0.9586 - new_score: 0.9607 - val_loss: 0.7323 - val_acc: 0.8432 - val_new_score: 0.8499\n",
      "Epoch 73/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1162 - acc: 0.9647 - new_score: 0.9670 - val_loss: 0.6817 - val_acc: 0.8603 - val_new_score: 0.8652\n",
      "Epoch 74/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1115 - acc: 0.9674 - new_score: 0.9685 - val_loss: 0.6308 - val_acc: 0.8663 - val_new_score: 0.8702\n",
      "Epoch 75/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1235 - acc: 0.9627 - new_score: 0.9639 - val_loss: 0.7268 - val_acc: 0.8422 - val_new_score: 0.8476\n",
      "Epoch 76/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1314 - acc: 0.9615 - new_score: 0.9632 - val_loss: 0.8071 - val_acc: 0.8372 - val_new_score: 0.8400\n",
      "Epoch 77/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1372 - acc: 0.9582 - new_score: 0.9585 - val_loss: 0.5957 - val_acc: 0.8693 - val_new_score: 0.8744\n",
      "Epoch 78/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1213 - acc: 0.9624 - new_score: 0.9646 - val_loss: 0.7473 - val_acc: 0.8518 - val_new_score: 0.8605\n",
      "Epoch 79/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1166 - acc: 0.9670 - new_score: 0.9673 - val_loss: 0.5774 - val_acc: 0.8719 - val_new_score: 0.8800\n",
      "Epoch 80/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1146 - acc: 0.9656 - new_score: 0.9669 - val_loss: 0.6663 - val_acc: 0.8719 - val_new_score: 0.8765\n",
      "Epoch 81/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1224 - acc: 0.9637 - new_score: 0.9650 - val_loss: 0.8607 - val_acc: 0.8357 - val_new_score: 0.8433\n",
      "Epoch 82/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1126 - acc: 0.9650 - new_score: 0.9657 - val_loss: 0.7615 - val_acc: 0.8538 - val_new_score: 0.8572\n",
      "Epoch 83/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1170 - acc: 0.9641 - new_score: 0.9657 - val_loss: 0.6616 - val_acc: 0.8618 - val_new_score: 0.8655\n",
      "Epoch 84/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1045 - acc: 0.9665 - new_score: 0.9682 - val_loss: 0.8289 - val_acc: 0.8477 - val_new_score: 0.8508\n",
      "Epoch 85/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1173 - acc: 0.9652 - new_score: 0.9663 - val_loss: 0.6641 - val_acc: 0.8628 - val_new_score: 0.8644\n",
      "Epoch 86/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1109 - acc: 0.9651 - new_score: 0.9665 - val_loss: 0.7351 - val_acc: 0.8593 - val_new_score: 0.8634\n",
      "Epoch 87/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0999 - acc: 0.9698 - new_score: 0.9711 - val_loss: 0.8172 - val_acc: 0.8482 - val_new_score: 0.8530\n",
      "Epoch 88/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1156 - acc: 0.9646 - new_score: 0.9661 - val_loss: 0.6413 - val_acc: 0.8709 - val_new_score: 0.8773\n",
      "Epoch 89/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0967 - acc: 0.9694 - new_score: 0.9704 - val_loss: 0.8079 - val_acc: 0.8503 - val_new_score: 0.8568\n",
      "Epoch 90/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1056 - acc: 0.9691 - new_score: 0.9689 - val_loss: 0.8731 - val_acc: 0.8337 - val_new_score: 0.8405\n",
      "Epoch 91/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1155 - acc: 0.9665 - new_score: 0.9678 - val_loss: 0.6641 - val_acc: 0.8633 - val_new_score: 0.8708\n",
      "Epoch 92/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1084 - acc: 0.9676 - new_score: 0.9693 - val_loss: 0.6382 - val_acc: 0.8668 - val_new_score: 0.8735\n",
      "Epoch 93/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0892 - acc: 0.9729 - new_score: 0.9745 - val_loss: 0.7321 - val_acc: 0.8598 - val_new_score: 0.8645\n",
      "Epoch 94/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0997 - acc: 0.9688 - new_score: 0.9701 - val_loss: 0.7012 - val_acc: 0.8658 - val_new_score: 0.8709\n",
      "Epoch 95/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1153 - acc: 0.9635 - new_score: 0.9652 - val_loss: 0.7884 - val_acc: 0.8437 - val_new_score: 0.8484\n",
      "Epoch 96/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1001 - acc: 0.9659 - new_score: 0.9673 - val_loss: 0.6695 - val_acc: 0.8789 - val_new_score: 0.8828\n",
      "Epoch 97/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0964 - acc: 0.9705 - new_score: 0.9720 - val_loss: 0.6439 - val_acc: 0.8754 - val_new_score: 0.8803\n",
      "Epoch 98/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1057 - acc: 0.9684 - new_score: 0.9693 - val_loss: 0.6182 - val_acc: 0.8724 - val_new_score: 0.8767\n",
      "Epoch 99/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0950 - acc: 0.9702 - new_score: 0.9719 - val_loss: 0.9496 - val_acc: 0.8387 - val_new_score: 0.8395\n",
      "Epoch 100/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1063 - acc: 0.9674 - new_score: 0.9692 - val_loss: 0.7183 - val_acc: 0.8658 - val_new_score: 0.8693\n",
      "Epoch 101/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1057 - acc: 0.9696 - new_score: 0.9708 - val_loss: 0.6597 - val_acc: 0.8714 - val_new_score: 0.8763\n",
      "Epoch 102/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0869 - acc: 0.9740 - new_score: 0.9746 - val_loss: 0.7356 - val_acc: 0.8658 - val_new_score: 0.8703\n",
      "Epoch 103/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1034 - acc: 0.9709 - new_score: 0.9722 - val_loss: 0.6404 - val_acc: 0.8709 - val_new_score: 0.8757\n",
      "Epoch 104/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0915 - acc: 0.9729 - new_score: 0.9741 - val_loss: 0.7143 - val_acc: 0.8749 - val_new_score: 0.8797\n",
      "Epoch 105/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0878 - acc: 0.9749 - new_score: 0.9768 - val_loss: 0.6657 - val_acc: 0.8724 - val_new_score: 0.8779\n",
      "Epoch 106/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0816 - acc: 0.9756 - new_score: 0.9762 - val_loss: 0.8017 - val_acc: 0.8487 - val_new_score: 0.8560\n",
      "Epoch 107/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1011 - acc: 0.9686 - new_score: 0.9707 - val_loss: 0.7825 - val_acc: 0.8538 - val_new_score: 0.8591\n",
      "Epoch 108/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0880 - acc: 0.9744 - new_score: 0.9755 - val_loss: 0.8844 - val_acc: 0.8447 - val_new_score: 0.8515\n",
      "Epoch 109/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.1091 - acc: 0.9661 - new_score: 0.9683 - val_loss: 0.8468 - val_acc: 0.8492 - val_new_score: 0.8570\n",
      "Epoch 110/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0822 - acc: 0.9731 - new_score: 0.9736 - val_loss: 0.9041 - val_acc: 0.8312 - val_new_score: 0.8377\n",
      "Epoch 111/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0913 - acc: 0.9712 - new_score: 0.9725 - val_loss: 0.7641 - val_acc: 0.8633 - val_new_score: 0.8696\n",
      "Epoch 112/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0975 - acc: 0.9730 - new_score: 0.9735 - val_loss: 0.6630 - val_acc: 0.8744 - val_new_score: 0.8777\n",
      "Epoch 113/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0846 - acc: 0.9744 - new_score: 0.9752 - val_loss: 0.6661 - val_acc: 0.8784 - val_new_score: 0.8839\n",
      "Epoch 114/500\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.0755 - acc: 0.9791 - new_score: 0.9798 - val_loss: 0.7431 - val_acc: 0.8663 - val_new_score: 0.8732\n",
      "Epoch 115/500\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 0.0941 - acc: 0.9728 - new_score: 0.9742 - val_loss: 0.7979 - val_acc: 0.8578 - val_new_score: 0.8597\n",
      "Epoch 116/500\n",
      " 54/250 [=====>........................] - ETA: 1:16 - loss: 0.0769 - acc: 0.9763 - new_score: 0.9773"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6d4a58b46876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m hist = model.fit_generator( train_generator, initial_epoch=0, epochs = 500, validation_data=val_generator, \n\u001b[1;32m      3\u001b[0m                            \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                            steps_per_epoch=len(x_train)/batch_size, validation_steps=len(x_val)/batch_size)\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorgpu36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# epochs = 100\n",
    "hist = model.fit_generator( train_generator, initial_epoch=0, epochs = 500, validation_data=val_generator, \n",
    "                           callbacks=[tensorboard, cp_callback, es_callback],\n",
    "                           steps_per_epoch=len(x_train)/batch_size, validation_steps=len(x_val)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8398368277549744, 0.8225, 0.8272113695144653]\n"
     ]
    }
   ],
   "source": [
    "# hist = model.evaluate( x_val/255., y_val_onehot, batch_size=30, verbose=1 )\n",
    "hist = model.evaluate_generator(val_generator, steps=len(x_val)/batch_size)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('car-v4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data load for submission\n",
    "x_test = np.load('x_test.npy')\n",
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one model submission \n",
    "if False:\n",
    "    predictions = model.predict( x_test )\n",
    "    pdi = np.argmax(predictions, axis=1)\n",
    "    print(pdi, np.min(pdi), np.max(pdi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/psychic/.conda/envs/tensorgpu36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "model 0 : car-v7-1.ckpt\n",
      "prediction 0 : [[5.04778999e-13 8.06876679e-34 3.18684866e-37 ... 5.79559443e-20\n",
      "  4.45941086e-28 1.00495543e-19]\n",
      " [2.30246054e-17 6.00929261e-15 2.18740617e-17 ... 8.53332507e-18\n",
      "  1.11519810e-12 1.57725095e-15]\n",
      " [5.66823451e-29 2.05291433e-29 1.27076220e-34 ... 3.32666342e-26\n",
      "  5.61155889e-24 1.41141608e-19]\n",
      " ...\n",
      " [3.05939642e-37 4.21654283e-20 2.43096174e-29 ... 1.06446619e-22\n",
      "  1.23219102e-22 3.02187581e-28]\n",
      " [6.21717758e-30 5.89227081e-26 1.06836250e-31 ... 3.38420318e-25\n",
      "  1.00382858e-09 8.78503272e-23]\n",
      " [1.04669512e-23 8.67514456e-19 8.13487868e-28 ... 1.06348965e-17\n",
      "  4.07121949e-12 1.73932161e-17]]\n",
      "model 1 : car-v6-3.ckpt\n",
      "prediction 1 : [[1.2762395e-10 8.7176092e-28 1.1498514e-23 ... 1.9232753e-15\n",
      "  2.5828481e-18 7.6482897e-20]\n",
      " [1.7412784e-22 1.3850753e-19 1.9273750e-15 ... 3.0439768e-20\n",
      "  6.6791220e-24 1.0849770e-15]\n",
      " [3.7934247e-26 7.8205616e-35 0.0000000e+00 ... 6.3774003e-37\n",
      "  5.2217565e-19 5.3851069e-12]\n",
      " ...\n",
      " [2.9559268e-31 1.3363117e-22 9.3726398e-19 ... 1.7119390e-18\n",
      "  4.0132889e-21 1.4753001e-25]\n",
      " [7.4709080e-27 4.2701739e-15 1.1510589e-19 ... 1.6091420e-25\n",
      "  2.9585190e-14 2.5459461e-14]\n",
      " [1.2882154e-18 5.9653020e-14 5.8547395e-23 ... 7.4473891e-23\n",
      "  4.5201807e-12 3.0315089e-14]]\n",
      "model 2 : car-v6-2.ckpt\n",
      "prediction 2 : [[2.5586809e-08 2.0625900e-21 1.0776142e-23 ... 1.7782306e-09\n",
      "  3.0798810e-21 4.2952584e-17]\n",
      " [6.7898754e-15 2.0710977e-20 4.7976684e-17 ... 3.8309962e-15\n",
      "  5.1331700e-23 9.8329217e-16]\n",
      " [1.5566220e-34 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  1.3877819e-35 2.7579810e-24]\n",
      " ...\n",
      " [2.3711307e-26 2.2271912e-18 4.5691041e-23 ... 3.8528432e-16\n",
      "  3.1127353e-22 1.8037079e-28]\n",
      " [7.0046473e-27 6.0643362e-25 1.0483855e-27 ... 3.6107019e-30\n",
      "  1.9788999e-09 4.6731433e-17]\n",
      " [1.4222429e-26 6.4748017e-25 1.6914002e-32 ... 4.2416717e-29\n",
      "  3.2503159e-15 4.2484594e-28]]\n",
      "final: [123  97 156 ...  43  49  93] 0 195\n"
     ]
    }
   ],
   "source": [
    "# ensamble. submission.\n",
    "# model = load_mode('car-v4.h5')\n",
    "if True:\n",
    "#     mo = load_model(mp, custom_objects={'new_score': new_score})\n",
    "    inputs = Input(shape=(224,224,3))\n",
    "    net = xception.Xception(input_tensor=inputs, input_shape=(224, 224, 3), include_top=False, pooling='max')\n",
    "    net2 = Dense(224, activation='relu') (net.layers[-1].output)\n",
    "    net2 = Dense(196)(net2)\n",
    "    net2 = Softmax(196)(net2)\n",
    "    model = Model(inputs=inputs, outputs=net2)\n",
    "    predictions=[]\n",
    "#     for ff in range(1, fold_k+1):\n",
    "#         mp='car-v4-'+str(ff)+'.ckpt'\n",
    "    for ff, mp in enumerate(['car-v7-1.ckpt', 'car-v6-3.ckpt', 'car-v6-2.ckpt']):\n",
    "        print('model',ff,':', mp)\n",
    "        model.load_weights(mp)\n",
    "        pr = model.predict( x_test )\n",
    "        predictions.append(pr)\n",
    "        print('prediction',ff,':',pr)\n",
    "    predictions = np.asarray(predictions)\n",
    "    prk = np.sum(predictions, axis=0 )\n",
    "    pdi = np.argmax(prk, axis=1)\n",
    "    print('final:', pdi, np.min(pdi), np.max(pdi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_file</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_00001.jpg</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_00002.jpg</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_00003.jpg</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_00004.jpg</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_00005.jpg</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         img_file  class\n",
       "0  test_00001.jpg    124\n",
       "1  test_00002.jpg     98\n",
       "2  test_00003.jpg    157\n",
       "3  test_00004.jpg     94\n",
       "4  test_00005.jpg     18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(basedir+'sample_submission.csv')\n",
    "submission[\"class\"] = pdi + 1  # class [0,195] to [1,196]  \n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdcf95146a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(submission[\"class\"], order=submission[\"class\"].value_counts(ascending=True).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
