{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications import xception\n",
    "from keras.applications import resnet50\n",
    "from keras.applications import mobilenetv2\n",
    "# from efficientnet import EfficientNetB3\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dropout, MaxPooling2D, Flatten, Dense, Softmax\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, K\n",
    "from keras.models import Input, Model\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modeldir= ../input/carmodel6/model/\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "bKaggle = True\n",
    "bDebug = False   # train data test.\n",
    "\n",
    "datadir = './pre/'\n",
    "modeldir = './pre/'\n",
    "inputdir='./'\n",
    "if bKaggle:\n",
    "    datadir = '../input/carmodel5/ppcarmodel/'\n",
    "    modeldir = '../input/carmodel6/model/'\n",
    "    inputdir = '../input/2019-3rd-ml-month-with-kakr/'\n",
    "\n",
    "print('modeldir=', modeldir)\n",
    "\n",
    "imagesize=250\n",
    "\n",
    "def dbgprint(msg):\n",
    "    if bKaggle:\n",
    "        os.system('echo \"'+msg+'\"')\n",
    "    else:\n",
    "        print(msg)\n",
    "dbgprint('hello log')\n",
    "\n",
    "\n",
    "def new_score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = (true_positives + K.epsilon()) / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = (true_positives + K.epsilon()) / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data verify.\n",
      "Found 6150 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# test generator\n",
    "\n",
    "if bDebug:\n",
    "    print('debug: train data verify.')\n",
    "    dftrain = pd.read_csv(inputdir+'train.csv')\n",
    "    dftrain['class'] = dftrain['class'].astype('str')\n",
    "    dftest = dftrain.iloc[8000:,:]\n",
    "    targetdir = datadir+'train'\n",
    "else:\n",
    "    print('test data verify.')\n",
    "    dftest = pd.read_csv(inputdir+'test.csv')\n",
    "    targetdir = datadir+'test'\n",
    "\n",
    "classes = list(str(num) for num in range(1,197))\n",
    "\n",
    "batch_size=32\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=dftest, \n",
    "                                             directory=targetdir,\n",
    "                                             x_col = 'img_file', \n",
    "                                             class_mode = None,\n",
    "                                             target_size = (imagesize, imagesize),\n",
    "                                             batch_size=batch_size, shuffle=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ../input/carmodel6/model/carmodel-v5-1-xception-129-0.8921.ckpt\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "if True:\n",
    "    inputs = Input(shape=(imagesize,imagesize,3))\n",
    "    net = xception.Xception(input_tensor=inputs, input_shape=(imagesize, imagesize, 3), include_top=False, weights='imagenet', pooling='max')\n",
    "    net2 = Dense(256, activation='relu') (net.layers[-1].output)\n",
    "    net2 = Dense(196, activation='softmax')(net2)\n",
    "    model = Model(inputs=inputs, outputs=net2)\n",
    "    mp = glob.glob(modeldir+'carmodel-v5-1-'+'*')[0]\n",
    "    print('model:', mp)\n",
    "    model.load_weights(mp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_img_array(filenames):\n",
    "    nps = []\n",
    "    for filename in filenames:\n",
    "        if os.path.exists(datadir+'test/'+filename):\n",
    "            # load image and flip horizontally\n",
    "            img = Image.open(datadir+'test/'+filename)\n",
    "            img = img.resize((imagesize, imagesize))\n",
    "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            npimg = np.asarray(img)\n",
    "            nps.append(npimg)\n",
    "        else:\n",
    "            print('not found ', filename)\n",
    "    return np.asarray(nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 (250, 250, 3)\n",
      "1000 (250, 250, 3)\n",
      "1000 (250, 250, 3)\n",
      "1000 (250, 250, 3)\n",
      "1000 (250, 250, 3)\n",
      "1000 (250, 250, 3)\n",
      "150 (250, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "# test code\n",
    "\n",
    "bulksize = 2000\n",
    "idxstart = 0\n",
    "idxend = bulksize\n",
    "preds = []\n",
    "for i in range(len(dftest)//bulksize+1):\n",
    "    idxstart = i*bulksize\n",
    "    idxend = (i+1)*bulksize if (i+1)*bulksize < len(dftest) else len(dftest)\n",
    "    nptest = load_img_array(dftest['img_file'][idxstart:idxend])\n",
    "    nptest = nptest / 255.0\n",
    "    print(len(nptest), nptest[0].shape)\n",
    "    # predict\n",
    "    pred = model.predict(nptest)\n",
    "    preds.append(pred)\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_generator\n",
      "193/192 [==============================] - 24s 124ms/step\n"
     ]
    }
   ],
   "source": [
    "# test code\n",
    "\n",
    "print('predict_generator')\n",
    "test_generator.reset()\n",
    "pr = model.predict_generator( test_generator , steps=len(dftest)/batch_size, verbose=1)\n",
    "\n",
    "print(np.argmax(preds, axis=1))\n",
    "print(np.argmax(pr, axis=1))\n",
    "\n",
    "match = np.sum(np.argmax(preds, axis=1)==np.argmax(pr, axis=1))\n",
    "print(match, '/', len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method= xception\n",
      "model 1 : ../input/carmodel6/model/carmodel-v5-1-xception-129-0.8921.ckpt\n",
      "predict_generator\n",
      "193/192 [==============================] - 25s 129ms/step\n",
      "prediction 0 : [[5.0705599e-15 0.0000000e+00 0.0000000e+00 ... 5.8705917e-21\n",
      "  3.1356052e-30 0.0000000e+00]\n",
      " [3.6794965e-23 1.0713371e-32 3.2272692e-19 ... 1.9632371e-15\n",
      "  9.9999988e-01 3.3179943e-21]\n",
      " [0.0000000e+00 7.4608209e-32 5.0946626e-14 ... 9.6230071e-29\n",
      "  1.9218804e-32 5.9936325e-25]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 1.7745896e-32 ... 3.8539011e-24\n",
      "  3.6936995e-31 1.9371078e-33]\n",
      " [1.3905494e-33 0.0000000e+00 9.3787864e-20 ... 3.3457393e-37\n",
      "  1.6736243e-23 9.7038796e-15]\n",
      " [5.7036223e-29 1.0914294e-35 1.5710641e-21 ... 1.3400677e-14\n",
      "  8.5120734e-27 2.1077964e-25]]\n",
      "(6150, 196)\n",
      "2000 (250, 250, 3)\n",
      "2000 (250, 250, 3)\n",
      "2000 (250, 250, 3)\n",
      "150 (250, 250, 3)\n",
      "(6150, 196)\n",
      "method= xception\n",
      "model 2 : ../input/carmodel6/model/carmodel-v5-2-xception-052-0.8709.ckpt\n",
      "predict_generator\n",
      "193/192 [==============================] - 25s 132ms/step\n",
      "prediction 1 : [[3.7113037e-05 6.5973660e-10 7.7475101e-19 ... 2.4335386e-10\n",
      "  1.0921721e-14 8.3124205e-15]\n",
      " [3.0828625e-25 2.3075813e-27 6.3862943e-15 ... 2.9651450e-17\n",
      "  9.9999011e-01 3.2378351e-16]\n",
      " [3.2826291e-37 2.2831791e-23 1.2548028e-11 ... 5.9554912e-29\n",
      "  3.0791398e-20 8.6291037e-21]\n",
      " ...\n",
      " [5.4007447e-36 2.2829661e-29 9.2634350e-16 ... 1.9022913e-13\n",
      "  4.4392279e-21 2.8027012e-15]\n",
      " [1.2635518e-26 1.7990482e-29 3.2188139e-09 ... 3.3125560e-21\n",
      "  6.5581058e-13 5.0954272e-11]\n",
      " [2.8231196e-22 6.0564420e-20 5.0368723e-19 ... 2.7812058e-08\n",
      "  1.4144732e-21 2.8733586e-22]]\n",
      "(6150, 196)\n",
      "2000 (250, 250, 3)\n",
      "2000 (250, 250, 3)\n",
      "2000 (250, 250, 3)\n",
      "150 (250, 250, 3)\n",
      "(6150, 196)\n",
      "method= xception\n",
      "model 3 : ../input/carmodel6/model/carmodel-v5-3-xception-147-0.9061.ckpt\n",
      "predict_generator\n",
      "193/192 [==============================] - 25s 130ms/step\n",
      "prediction 2 : [[1.7003904e-10 2.9221950e-25 3.5533901e-27 ... 1.3617826e-29\n",
      "  1.8232488e-27 1.9555635e-24]\n",
      " [1.0119173e-18 4.8953143e-25 1.7445651e-11 ... 1.8443593e-17\n",
      "  1.0000000e+00 2.4095231e-15]\n",
      " [0.0000000e+00 0.0000000e+00 7.8720871e-24 ... 0.0000000e+00\n",
      "  7.4542868e-37 3.0224441e-26]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 3.5618149e-32 ... 6.4046063e-30\n",
      "  0.0000000e+00 2.7742278e-26]\n",
      " [0.0000000e+00 0.0000000e+00 1.8968863e-21 ... 0.0000000e+00\n",
      "  2.2389560e-33 4.8502355e-26]\n",
      " [1.2842618e-28 1.0538290e-28 1.4262473e-27 ... 9.2341851e-14\n",
      "  1.1264151e-25 2.3370231e-28]]\n",
      "(6150, 196)\n",
      "2000 (250, 250, 3)\n",
      "2000 (250, 250, 3)\n",
      "2000 (250, 250, 3)\n",
      "150 (250, 250, 3)\n",
      "(6150, 196)\n",
      "method= xception\n",
      "model 4 : ../input/carmodel6/model/carmodel-v5-4-xception-107-0.9010.ckpt\n",
      "predict_generator\n",
      "193/192 [==============================] - 26s 135ms/step\n",
      "prediction 3 : [[3.5339363e-16 0.0000000e+00 0.0000000e+00 ... 6.7664856e-33\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [6.3609989e-20 3.0939204e-15 6.0108602e-12 ... 1.4380833e-10\n",
      "  9.9676150e-01 4.8003335e-09]\n",
      " [5.8380700e-38 2.8724193e-19 1.7314268e-16 ... 2.3205280e-34\n",
      "  3.4166466e-32 2.0133630e-37]\n",
      " ...\n",
      " [0.0000000e+00 7.2420738e-29 1.7417755e-13 ... 2.5413033e-23\n",
      "  9.4408308e-22 2.6136213e-18]\n",
      " [3.0414490e-27 7.6663131e-30 1.1135147e-09 ... 1.2366562e-30\n",
      "  8.7936234e-24 5.4115311e-13]\n",
      " [1.1333936e-23 3.8506734e-20 5.6193408e-23 ... 6.0383801e-17\n",
      "  3.8187330e-31 9.6846907e-20]]\n",
      "(6150, 196)\n",
      "2000 (250, 250, 3)\n",
      "2000 (250, 250, 3)\n",
      "2000 (250, 250, 3)\n",
      "150 (250, 250, 3)\n",
      "(6150, 196)\n",
      "method= xception\n",
      "model 5 : ../input/carmodel6/model/carmodel-v5-5-xception-112-0.8961.ckpt\n",
      "predict_generator\n",
      "193/192 [==============================] - 26s 132ms/step\n",
      "prediction 4 : [[5.5269296e-12 2.1912945e-30 2.6027058e-28 ... 6.7800891e-22\n",
      "  2.6203566e-22 0.0000000e+00]\n",
      " [5.9528388e-27 1.3233761e-29 8.4620478e-19 ... 6.7886688e-18\n",
      "  9.9999988e-01 6.6241349e-16]\n",
      " [0.0000000e+00 9.2686804e-33 5.6425451e-15 ... 7.7682369e-26\n",
      "  2.2229296e-34 1.0657096e-22]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 1.3436097e-24 ... 2.1834543e-27\n",
      "  1.1324830e-30 2.9736603e-31]\n",
      " [3.8487701e-26 2.0139020e-28 1.5480630e-14 ... 3.8974794e-27\n",
      "  4.0517428e-22 1.4376686e-13]\n",
      " [2.0905815e-37 0.0000000e+00 4.8506129e-23 ... 2.0492129e-17\n",
      "  4.2039620e-30 8.5588014e-17]]\n",
      "(6150, 196)\n",
      "2000 (250, 250, 3)\n",
      "2000 (250, 250, 3)\n",
      "2000 (250, 250, 3)\n",
      "150 (250, 250, 3)\n",
      "(6150, 196)\n",
      "method= xception\n",
      "model 6 : ../input/carmodel6/model/carmodel-v5-6-xception-100-0.8981.ckpt\n",
      "predict_generator\n",
      "193/192 [==============================] - 27s 138ms/step\n",
      "prediction 5 : [[2.80739543e-10 2.56699352e-22 9.77927827e-18 ... 1.97355118e-10\n",
      "  3.69352849e-20 6.96198463e-24]\n",
      " [1.64201701e-20 4.67977870e-12 1.85760740e-08 ... 1.65287489e-11\n",
      "  9.99807537e-01 1.60456232e-11]\n",
      " [3.22286163e-36 3.16626856e-22 4.11818419e-16 ... 1.11148316e-27\n",
      "  1.01680114e-32 1.23366027e-19]\n",
      " ...\n",
      " [0.00000000e+00 4.55467879e-38 9.42649770e-26 ... 8.38093912e-25\n",
      "  3.62390389e-30 1.72726103e-27]\n",
      " [2.29578969e-26 1.72427765e-23 2.25432303e-12 ... 3.32386735e-19\n",
      "  3.85065889e-16 1.46081589e-15]\n",
      " [1.38725393e-25 1.06960781e-28 1.62107442e-15 ... 1.32902171e-14\n",
      "  1.37595412e-25 1.11445134e-18]]\n",
      "(6150, 196)\n",
      "2000 (250, 250, 3)\n",
      "2000 (250, 250, 3)\n",
      "2000 (250, 250, 3)\n",
      "150 (250, 250, 3)\n",
      "(6150, 196)\n"
     ]
    }
   ],
   "source": [
    "# model predict\n",
    "model_cnt=0\n",
    "if True:\n",
    "    predictions=[]\n",
    "    modellist = ['carmodel-v5-1-', 'carmodel-v5-2-', 'carmodel-v5-3-','carmodel-v5-4-', 'carmodel-v5-5-', 'carmodel-v5-6-' ]\n",
    "#     modellist = ['carmodel-v5-1-']\n",
    "    for ff, mp in enumerate(modellist):\n",
    "        files = glob.glob(modeldir+mp+'*')\n",
    "        if len(files)==0:\n",
    "            print('not found model:', mp)\n",
    "            continue\n",
    "        mp = max(files, key=os.path.getctime)\n",
    "        msg = '{} model={}'.format(ff, mp)\n",
    "        dbgprint(msg)\n",
    "        model_cnt+=1\n",
    "        \n",
    "        method='xception'\n",
    "        if mp.find('resnet50')>0:\n",
    "            method = 'resnet50'\n",
    "        elif mp.find('mobilenetv2')>0:\n",
    "            method = 'mobilenetv2'\n",
    "        elif mp.find('efficientnetb3')>0:\n",
    "            method = 'efficientnetb3'\n",
    "        \n",
    "        inputs = Input(shape=(imagesize,imagesize,3))\n",
    "        print('method=', method)\n",
    "        if method=='xception':\n",
    "            net = xception.Xception(input_tensor=inputs, input_shape=(imagesize, imagesize, 3), include_top=False, weights='imagenet', pooling='max')\n",
    "        elif method=='resnet50':\n",
    "            net = resnet50.ResNet50(input_tensor=inputs, input_shape=(imagesize, imagesize, 3), include_top=False, weights='imagenet', pooling='max')\n",
    "        elif method=='mobilenetv2':\n",
    "            net = mobilenetv2.MobileNetV2(input_tensor=inputs, input_shape=(imagesize, imagesize, 3), include_top=False, weights='imagenet', pooling='max')\n",
    "        elif method=='efficientnetb3':\n",
    "            net = EfficientNetB3(input_tensor=inputs, input_shape=(imagesize, imagesize, 3), include_top=False, weights='imagenet', pooling='max')\n",
    "        net2 = Dense(256, activation='relu') (net.layers[-1].output)\n",
    "        net2 = Dense(196, activation='softmax')(net2)\n",
    "        model = Model(inputs=inputs, outputs=net2)\n",
    "        \n",
    "        print('model',ff+1,':', mp)\n",
    "        model.load_weights(mp)\n",
    "        \n",
    "        print('predict_generator')\n",
    "        test_generator.reset()\n",
    "        pr = model.predict_generator( test_generator , steps=len(dftest)/batch_size, verbose=1)\n",
    "        predictions.append(pr)\n",
    "        print('prediction',ff+1,':',pr)\n",
    "        print(pr.shape)\n",
    "        \n",
    "        # TTA\n",
    "        bulksize = 2000\n",
    "        idxstart = 0\n",
    "        idxend = bulksize\n",
    "        preds = []\n",
    "        for i in range(len(dftest)//bulksize+1):\n",
    "            idxstart = i*bulksize\n",
    "            idxend = (i+1)*bulksize if (i+1)*bulksize < len(dftest) else len(dftest)\n",
    "            nptest = load_img_array(dftest['img_file'][idxstart:idxend])\n",
    "            nptest = nptest / 255.0\n",
    "            print(len(nptest), nptest[0].shape)\n",
    "            # predict\n",
    "            pred = model.predict(nptest)\n",
    "            preds.append(pred)\n",
    "\n",
    "        preds = np.concatenate(preds, axis=0)\n",
    "        print(preds.shape)\n",
    "        predictions.append(preds)\n",
    "\n",
    "#         print('predict')\n",
    "#         pr2 = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dftest count= 6150\n",
      "model count= 6\n",
      "model result count= 12\n",
      "each result count= (6150, 196)\n"
     ]
    }
   ],
   "source": [
    "print('dftest count=', len(dftest))\n",
    "print('model count=', model_cnt)\n",
    "print('model result count=', len(predictions))\n",
    "print('each result count=', predictions[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    predictions=[]\n",
    "    test_generator.reset()\n",
    "    pr = model.predict_generator( test_generator , steps=len(dftest)/batch_size, verbose=1 )\n",
    "    # steps=len(dftest)/batchsize\n",
    "    predictions.append(pr)\n",
    "    print('prediction',ff,':',pr)\n",
    "    print(pr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predict result. how similar? \n",
    "model1_pr=np.argmax(predictions[0], axis=1)\n",
    "model2_pr=np.argmax(predictions[1], axis=1)\n",
    "model3_pr=np.argmax(predictions[2], axis=1)\n",
    "print(model1_pr)\n",
    "print(model2_pr)\n",
    "print(model3_pr)\n",
    "\n",
    "# model 3 all matched ratio \n",
    "samecnt = np.sum(np.bitwise_and(model1_pr==model2_pr, model1_pr==model3_pr))\n",
    "print(samecnt, '/', len(model1_pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble result.....\n",
    "if True:\n",
    "    # ensemble~~~~~  mean value. \n",
    "    predictions = np.asarray(predictions)\n",
    "    prk = np.mean(predictions, axis=0 )\n",
    "    # index class. need to change to label.\n",
    "    pdi = np.argmax(prk, axis=1)  \n",
    "    print('ensemble class index:', pdi,  'min=', np.min(pdi), 'max=', np.max(pdi))\n",
    "    sns.countplot(pdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to LABEL...\n",
    "if True:\n",
    "    # labeling k=label string, v=class number\n",
    "#     label = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "#     final_pred = [label[k] for k in pdi]\n",
    "    \n",
    "    n1=pd.DataFrame(list(range(1,197)), columns=['num']).astype('str')\n",
    "    n2=n1.sort_values('num').values.squeeze()\n",
    "    final_pred = [n2[k] for k in pdi]\n",
    "    \n",
    "    final_pred = np.asarray(final_pred, dtype=np.int)\n",
    "    print('final:', final_pred)\n",
    "    print('count=', len(final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug result check\n",
    "if bDebug:\n",
    "    # evaluation (train data set. we knew the label.)\n",
    "    reallabel = np.array(dftest['class'].values, dtype=int)\n",
    "    print(reallabel)\n",
    "    print( np.sum(final_pred==reallabel), '/', len(final_pred), len(reallabel))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make submission file.\n",
    "if not bDebug:\n",
    "    submission = pd.read_csv(inputdir+'sample_submission.csv')\n",
    "    submission[\"class\"] = final_pred  \n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not bDebug:\n",
    "    sns.countplot(submission[\"class\"], order=submission[\"class\"].value_counts(ascending=True).index)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high rate predictions\n",
    "dfpredictions = pd.DataFrame(np.max(prk, axis=1).squeeze(), columns=['maxPr'])\n",
    "dfpredictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpredictions['maxPr'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psids = dfpredictions['maxPr']>0.99 \n",
    "print( np.sum(psids) , '/', len(dfpredictions) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    print('Create Pseudo Label')\n",
    "    dfpseudo = pd.DataFrame( dftest.loc[psids, 'img_file'] )\n",
    "    dfpseudo['class'] = final_pred[psids]\n",
    "    dfpseudo.to_csv('pseudo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpseudo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
