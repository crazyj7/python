{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# 경고 무시 (쓸데없는 로그 출력금지)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# 그래프 관련 \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n# 학습\nimport time\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nimport random\n\nimport keras\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dropout, MaxPool2D, Flatten, Dense, Softmax\nfrom keras.preprocessing import image\n\nfrom keras.utils import np_utils\nfrom keras.models import load_model\nfrom keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, K\nfrom keras.models import Input, Model\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom keras.preprocessing.image import ImageDataGenerator\nimport gc\n\n########################\n# Seed All\n# import numpy as np\nimport tensorflow as tf\nimport random\n# import os\n# from keras import backend as K\nimport warnings\nfrom keras.callbacks import Callback\nfrom datetime import datetime\nfrom pytz import timezone, utc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## load data\ninputdir='../input/Kannada-MNIST/'\noutputdir='./'\nmodelpath = '../input/mykannada/model.h5'\n\ndftrain = pd.read_csv(inputdir+'train.csv')\ndftest = pd.read_csv(inputdir+'test.csv')\ndfsub = pd.read_csv(inputdir+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nptrain = np.asarray(dftrain.iloc[:,1:].values)\nprint('test shape=', nptrain.shape)\n\nnptest = np.asarray(dftest.iloc[:,1:].values)\nprint('test shape=', nptest.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nptrain=nptrain.reshape((-1,28,28,1))\nprint('train shape=', nptrain.shape)\nnptest=nptest.reshape((-1,28,28,1))\nprint('test shape=', nptest.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_show(npdata, labels, cnt, brandom=True):\n    plt.figure(figsize=(6*cnt, 6))\n    if brandom:\n        idx=np.random.randint(0,npdata.shape[0], cnt)\n    else:\n        idx=np.arange(cnt)\n    for i in range(cnt):\n        plt.subplot(1,cnt, i+1)\n        plt.title(labels[idx[i]])\n        imgdata = npdata[idx[i]].squeeze()\n        plt.imshow(imgdata, cmap='gray')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train 이미지 랜덤 보기    \nimage_show(nptrain, dftrain.label, 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test 이미지 랜덤 보기\nimage_show(nptest, dftest.id, 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftrain.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image Augument"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen1 = ImageDataGenerator(rescale=1./255, shear_range=0.1, zoom_range=0.1, \n                              horizontal_flip=False, vertical_flip=False,\n                              width_shift_range=0.1, height_shift_range=0.1, \n                              rotation_range=15, brightness_range=[0.5, 1.2],\n                              fill_mode='nearest')\ndatagen2 = ImageDataGenerator(rescale=1./255)\n\ndatagen1.fit(nptrain)\nfor xbatch, ybatch in datagen1.flow(nptrain, dftrain['label'], batch_size=6):\n    image_show(xbatch, ybatch, 6, False)\n    break   \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for xbatch, ybatch in datagen1.flow(nptrain, dftrain['label'], batch_size=6):\n    image_show(xbatch, ybatch, 6, False)\n    break   \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"KST = timezone('Asia/Seoul')\n\ndef dbgprint(msg):\n    os.system(f'echo \\\"{msg}\\\"')\n    print(msg) \n\nclass EpochLogWrite(Callback):\n    def on_epoch_begin(self, epoch, logs={}):\n        tmx = utc.localize(datetime.utcnow()).astimezone(KST).time()\n        dbgprint('Epoch #{} begins at {}'.format(epoch+1, tmx))\n    def on_epoch_end(self, epoch, logs={}):\n        tmx = utc.localize(datetime.utcnow()).astimezone(KST).time()\n        dbgprint('Epoch #{} ends at {}  acc={} val_acc={} '.format(epoch+1, tmx, round(logs['acc'],4), round(logs['val_acc'],4)))\n\n\nSEED=1234\ndbgprint('hello world. SEED={}'.format(SEED))\n\ndef seed_All():\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    config = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n    tf.set_random_seed(SEED)\n    sess = tf.Session(graph=tf.get_default_graph(), config=config)\n    K.set_session(sess)\n\nseed_All()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#######################\n# configure\nbDebug=True\n# running mode\n# 0: train.\n# 1: test.\nrunmode = 0\n\n#######################\ncurFold = 1  # make current fold (1..fold_k)\nbatch_size=32  # 16, 32, 64  debug.. memory dependent!\n# K fold\nfold_k = 6\nimagesize=28\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if bDebug:\n    print('Debug Version!!!! ')\n    print('Fast Fast. Only use 1000 items in train.')\n    dftrain = dftrain[:1000]\n    nptrain = nptrain[:1000]\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"method = 'conv'\nmodelname = 'kannada-v1-'\nmodellist = [modelname+'1-', modelname+'2-', modelname+'3-', \n             modelname+'4-', modelname+'5-', modelname+'6-']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skf = StratifiedKFold(fold_k, random_state=SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if runmode==0:\n    # train\n   \n    kk=0\n    for modelname, (tri, tei) in zip(modellist, skf.split(nptrain, dftrain['label'])):\n        kk+=1\n        # 아래를 주석처리하면 전체 모델 생성으로 오랜 시간 소요.\n        # curFold (1~6) 해당 모델 1개만 생성.\n        if kk != curFold:\n            continue\n        dbgprint('Make Model={}'.format(kk))\n\n        modelpath = outputdir+modelname+method+'-{epoch:03d}-{val_acc:.4f}.ckpt'\n        print(modelpath)\n\n        nptrain_t = nptrain[tri,:]\n        nptrain_v = nptrain[tei,:]\n\n        dflabel_t = np_utils.to_categorical(dftrain.loc[tri]['label'])\n        dflabel_v = np_utils.to_categorical(dftrain.loc[tei]['label'])\n\n        datagen1 = ImageDataGenerator(rescale=1./255, shear_range=0.1, zoom_range=0.1, \n                                      horizontal_flip=False, vertical_flip=False,\n                                      width_shift_range=0.1, height_shift_range=0.1, \n                                      rotation_range=15, brightness_range=[0.5, 1.2],\n                                      fill_mode='nearest')\n        datagen2 = ImageDataGenerator(rescale=1./255)\n\n        datagen1.fit(nptrain_t)\n        train_generator = datagen1.flow(nptrain_t, dflabel_t, batch_size=batch_size, seed=SEED, shuffle=True)\n        val_generator = datagen1.flow(nptrain_v, dflabel_v, batch_size=batch_size,shuffle=False)   \n\n        ### checkpoint save weights in progress...\n        cp_callback = ModelCheckpoint(modelpath,  monitor='val_score', mode='max', save_best_only=True, \n                                      save_weights_only=False)\n        es_callback = EarlyStopping(monitor='val_score',  mode='max', patience=20)\n\n        # tensorboard log\n        if not os.path.exists('log'):\n            os.mkdir('log')\n        tensorboard = TensorBoard(log_dir='log/'+str(time.time()))\n\n        model = Sequential()\n\n        model.add(Conv2D(filters = 32, kernel_size = (4,4),padding = 'Same', activation ='relu', \n                         input_shape = (28,28,1)))\n        model.add(Conv2D(filters = 32, kernel_size = (4,4),padding = 'Same', activation ='relu'))\n        model.add(MaxPool2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n\n        model.add(Conv2D(filters = 64, kernel_size = (4,4),padding = 'Same', activation ='relu'))\n        model.add(MaxPool2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n\n        model.add(Conv2D(filters = 128, kernel_size = (4,4),padding = 'Same', activation ='relu'))\n        model.add(Dropout(0.25))\n\n        model.add(Conv2D(filters = 256, kernel_size = (4,4),padding = 'Same', activation ='relu'))\n        model.add(MaxPool2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n\n        model.add(Conv2D(filters = 128, kernel_size = (4,4),padding = 'Same', activation ='relu'))\n        model.add(Dropout(0.25))\n\n        model.add(Flatten())\n        model.add(Dense(256, activation='relu'))\n        model.add(Dropout(0.25))\n        model.add(Dense(10, activation='softmax'))\n\n        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n\n        model.summary()\n\n    #     cblist = [tensorboard, cp_callback, es_callback, EpochLogWrite()]\n        cblist = [EpochLogWrite(), es_callback, cp_callback]\n        epochs=100\n        hist = model.fit_generator( train_generator, initial_epoch=0, epochs = epochs, validation_data=val_generator, \n                                   callbacks=cblist, steps_per_epoch=len(tri)/batch_size, validation_steps=len(tei)/batch_size)\n\n        model.save(outputdir+'model.h5')   # create model file in CWD\nelse:\n    # test\n    print('test : load model')\n    model = load_model(modelpath) # load model from modelpath (dataset)\n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if runmode==1:\n    # test mode\n    datagen1 = ImageDataGenerator(rescale=1./255)\n    dflabel = np_utils.to_categorical(dftrain['label'])\n    print(nptrain.shape)\n    print(dflabel.shape)\n    eval_generator = datagen1.flow(nptrain, dflabel, batch_size=batch_size, shuffle=False)\n    score = model.evaluate_generator(eval_generator, steps=dflabel.shape[0]/batch_size)\n    # loss and acc\n    print(score)\n    # predict\n    result = model.predict_generator(eval_generator, steps=dflabel.shape[0]/batch_size)\n    \n    predict_result = np.argmax(result, axis=1)\n    print(predict_result)\n    print(dftrain['label'].values)\n    print('match cnt=', np.sum(predict_result==dftrain['label'].values))    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if runmode==1:\n    # test mode\n    datagen1 = ImageDataGenerator(rescale=1./255)\n    test_generator = datagen1.flow(nptest, batch_size=batch_size, shuffle=False)\n    result = model.predict_generator(test_generator, steps=len(nptest)/batch_size)\n    predict_result = np.argmax(result, axis=1)\n    print(predict_result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}